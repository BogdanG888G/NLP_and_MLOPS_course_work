from sqlalchemy import create_engine, text
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.empty import EmptyOperator
from datetime import datetime, timedelta
import logging
import os
import sys

# Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿ÑƒÑ‚ÑŒ Ğº Ğ¿Ğ°Ğ¿ĞºĞµ parsers Ğ² PYTHONPATH
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'parsers'))
sys.path.insert(0, '/opt/airflow/parsers')  # Ğ°Ğ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿ÑƒÑ‚ÑŒ

try:
    from irecommend_parser import ReviewParser
    logging.info("âœ… ReviewParser ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")
except ImportError as e:
    logging.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° ReviewParser: {e}")
    logging.info(f"Python path: {sys.path}")
    logging.info(f"Ğ¢ĞµĞºÑƒÑ‰Ğ°Ñ Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ñ: {os.getcwd()}")
    logging.info(f"Ğ¡Ğ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ parsers Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¸: {os.listdir('/opt/airflow/parsers')}")

BASE_URL = "https://irecommend.ru"
TOTAL_PAGES = 2  # Ğ”Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ° ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ¸Ğ¼ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†

def init_db():
    """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"""
    try:
        engine = create_engine('postgresql+psycopg2://airflow:airflow@postgres:5432/airflow')
        logging.info("âœ… ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ¾ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾")
        
        with engine.connect() as conn:
            result = conn.execute(text("SELECT 'HELLO, AIRFLOW!' as greeting"))
            row = result.fetchone()
            if row:
                greeting = row[0]
                logging.info(f"Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°: {greeting}")
            else:
                logging.info("Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ½Ğµ Ğ²ĞµÑ€Ğ½ÑƒĞ» Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²")
            
        return "database_connection_success"
        
    except Exception as e:
        logging.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…: {e}")
        raise

def parse_reviews():
    """Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğ° Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²"""
    try:
        logging.info("ğŸ”„ Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¿Ğ°Ñ€ÑĞµÑ€Ğ°...")
        
        parser = ReviewParser(BASE_URL)
        logging.info(f"ğŸ”„ ĞŸĞ°Ñ€ÑĞ¸Ğ¼ {TOTAL_PAGES} ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†...")
        
        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼
        reviews = parser.run_parsing(total_pages=TOTAL_PAGES)
        
        if reviews:
            os.makedirs('/opt/airflow/data/reviews', exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            csv_path = f'/opt/airflow/data/reviews/reviews_{timestamp}.csv'
            parser.save_to_csv(reviews, csv_path)
            
            logging.info(f"âœ… ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½. Ğ¡Ğ¾Ğ±Ñ€Ğ°Ğ½Ğ¾ {len(reviews)} Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²")
            logging.info(f"ğŸ’¾ Ğ¤Ğ°Ğ¹Ğ» ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½: {csv_path}")
            
            return f"Ğ£ÑĞ¿ĞµÑˆĞ½Ğ¾ ÑĞ¾Ğ±Ñ€Ğ°Ğ½Ğ¾ {len(reviews)} Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²"
        else:
            logging.warning("âš ï¸ ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ Ğ½Ğµ Ğ´Ğ°Ğ» Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²")
            return "Ğ¡Ğ¾Ğ±Ñ€Ğ°Ğ½Ğ¾ 0 Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ğ¾Ğ²"
            
    except Exception as e:
        logging.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ğµ: {e}")
        raise

# ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ DAG
with DAG(
    'parser_collect_data', 
    description='ĞŸĞ°Ñ€ÑĞµÑ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ iRecommend',
    start_date=datetime(2025, 10, 17),
    schedule_interval=None,
    catchup=False,
    tags=['parsing', 'data_collection'],
) as dag:
    
    start_task = EmptyOperator(
        task_id='start'
    )

    init_db_task = PythonOperator(
        task_id='init_db', 
        python_callable=init_db,
        execution_timeout=timedelta(minutes=5)
    )

    collect_data_task = PythonOperator(
        task_id="collect_data",
        python_callable=parse_reviews,
        execution_timeout=timedelta(minutes=5)
    )

    end_task = EmptyOperator(
        task_id='end'
    )

    start_task >> init_db_task >> collect_data_task >> end_task