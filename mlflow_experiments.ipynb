{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d05f1f49",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback, AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.metrics import *\n",
    "\n",
    "import joblib\n",
    "import cloudpickle\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from functools import lru_cache\n",
    "\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "import re\n",
    "import emoji\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bda6b4",
   "metadata": {},
   "source": [
    "# Настройка конфигураций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5623ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "import os\n",
    "\n",
    "def load_config(config_name):\n",
    "    \"\"\"Загрузка конфигурации для конкретного эксперимента\"\"\"\n",
    "    config_path = f\"configs/{config_name}.yml\"\n",
    "    \n",
    "    if not os.path.exists(config_path):\n",
    "        raise FileNotFoundError(f\"Конфигурационный файл {config_path} не найден\")\n",
    "    \n",
    "    # Загружаем основной конфиг\n",
    "    cfg = OmegaConf.load(config_path)\n",
    "    \n",
    "    # Переопределяем переменными окружения\n",
    "    if 'MLFLOW_TRACKING_URI' in os.environ:\n",
    "        cfg.mlflow.tracking_uri = os.environ['MLFLOW_TRACKING_URI']\n",
    "    \n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558efd8c",
   "metadata": {},
   "source": [
    "# Эксперименты с датасетами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e78b22",
   "metadata": {},
   "source": [
    "## Первый эксперимент (Лемматизация, удаление знаков пунктуации)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8ba75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!   mlflow server --host 127.0.0.1 --port 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3e922f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"base\")  # или другое имя вашего конфига\n",
    "\n",
    "# Теперь можно использовать\n",
    "mlflow.set_tracking_uri(cfg.mlflow.tracking_uri)\n",
    "\n",
    "print(f\"Tracking URI: {cfg.mlflow.tracking_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27692760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем конфигурацию\n",
    "cfg = load_config(\"preprocess_first\")\n",
    "\n",
    "# Инициализация компонентов\n",
    "analyzer = MorphAnalyzer(lang='ru')\n",
    "\n",
    "# Получаем стоп-слова из конфигурации\n",
    "stop_words = nltk.corpus.stopwords.words('russian')\n",
    "stop_words_cleaned = [\n",
    "    w for w in stop_words\n",
    "    if w not in cfg.preprocess.keep_words  # Теперь это должно работать\n",
    "]\n",
    "\n",
    "@lru_cache(maxsize=cfg.preprocess.lru_cache_size)\n",
    "def lemmatization(text):\n",
    "    return analyzer.parse(text)[0].normal_form\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(cfg.preprocess.regex.remove_newlines, \" \", text)\n",
    "\n",
    "    # 2. Фиксируем кривые слова nчипсы → чипсы\n",
    "    text = re.sub(cfg.preprocess.regex.fix_mistyped_n, r\"\\1\", text)\n",
    "\n",
    "    # 3. Убираем символы\n",
    "    text = re.sub(cfg.preprocess.regex.remove_symbols, \"\", text)\n",
    "\n",
    "    # 4. Чистим двойные пробелы\n",
    "    text = re.sub(cfg.preprocess.regex.collapse_spaces, \" \", text).strip()\n",
    "\n",
    "    # 5. Токенизация\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    result = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if token not in stop_words_cleaned:\n",
    "            result.append(lemmatization(token))\n",
    "\n",
    "    return \" \".join(result)\n",
    "\n",
    "# Проверка работы\n",
    "test_text = \"Всем привет! Какое же неприятное место, нет?\\n\"\n",
    "processed = preprocess_text(test_text)\n",
    "print(f\"Исходный: {test_text}\")\n",
    "print(f\"Обработанный: {processed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb52f206",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"First dataset\"):\n",
    "\n",
    "    mlflow.set_tag(\"Dataset_version\", cfg.mlflow.dataset_version)\n",
    "\n",
    "    # Загружаем все файлы из конфига\n",
    "    annotation_dfs = [\n",
    "        pd.read_json(path) for path in cfg.preprocess.input_files\n",
    "    ]\n",
    "\n",
    "    df_annotations = pd.concat(annotation_dfs)\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"span\", \"label\"])\n",
    "\n",
    "    for mark in df_annotations['aspect_sentiment']:\n",
    "        for entry in mark:\n",
    "            span = entry['text']\n",
    "            label = entry['labels'][0]\n",
    "            df.loc[len(df)] = [span, label]\n",
    "\n",
    "    # Применяем препроцессинг\n",
    "    df['span'] = df['span'].apply(preprocess_text)\n",
    "\n",
    "    display(df)\n",
    "\n",
    "    # Сохраняем датасет\n",
    "    df.to_csv(cfg.preprocess.output.dataset_csv, index=False)\n",
    "\n",
    "    mlflow.log_artifact(cfg.preprocess.output.dataset_csv, \"datasets\")\n",
    "\n",
    "    # Сохраняем препроцесс-функцию\n",
    "    with open(cfg.preprocess.output.preprocess_pickle, \"wb\") as f:\n",
    "        cloudpickle.dump(preprocess_text, f)\n",
    "\n",
    "    mlflow.log_artifact(cfg.preprocess.output.preprocess_pickle, \"functions\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee99a6cf",
   "metadata": {},
   "source": [
    "## Второй эксперимент (Простая очистка от знаков препинания и изменение эмодзи)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c7fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "cfg = load_config('preprocess_second')\n",
    "\n",
    "def clean_text_only(text, cfg=None):\n",
    "    \"\"\"\n",
    "    Очистка текста с поддержкой конфигурации\n",
    "    \n",
    "    Args:\n",
    "        text: Входной текст\n",
    "        cfg: Конфигурация (опционально)\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Если конфигурация не передана, используем значения по умолчанию\n",
    "    lowercase = getattr(cfg, 'clean_only', {}).get('lowercase', True) if cfg else True\n",
    "    replace_emoji = getattr(cfg, 'clean_only', {}).get('replace_emoji', True) if cfg else True\n",
    "    remove_punctuation = getattr(cfg, 'clean_only', {}).get('remove_punctuation', True) if cfg else True\n",
    "    remove_special_chars = getattr(cfg, 'clean_only', {}).get('remove_special_chars', True) if cfg else True\n",
    "    collapse_spaces = getattr(cfg, 'clean_only', {}).get('collapse_spaces', True) if cfg else True\n",
    "    \n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "    \n",
    "    # Заменяем эмодзи\n",
    "    if replace_emoji:\n",
    "        text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "    \n",
    "    # Удаляем переносы и спецсимволы\n",
    "    if remove_special_chars:\n",
    "        text = re.sub(r'[\\n\\r\\t]', ' ', text)\n",
    "    \n",
    "    # Удаляем пунктуацию\n",
    "    if remove_punctuation:\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Убираем лишние пробелы\n",
    "    if collapse_spaces:\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Версия для обратной совместимости (без конфигурации)\n",
    "def clean_text_only_legacy(text):\n",
    "    \"\"\"Легаси версия для обратной совместимости\"\"\"\n",
    "    return clean_text_only(text)\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name='Second dataset'):\n",
    "    \n",
    "    mlflow.set_tag(\"Dataset_version\", cfg.mlflow.dataset_version)\n",
    "\n",
    "    # Загружаем все файлы из конфига\n",
    "    annotation_dfs = [\n",
    "        pd.read_json(path) for path in cfg.preprocess.input_files\n",
    "    ]\n",
    "\n",
    "    df_annotations = pd.concat(annotation_dfs)\n",
    "    \n",
    "    df = pd.DataFrame(columns=[\"span\", \"label\"])\n",
    "\n",
    "    for mark in df_annotations['aspect_sentiment']:\n",
    "        for entry in mark:\n",
    "            span = entry['text']\n",
    "            label = entry['labels'][0]\n",
    "            df.loc[len(df)] = [span, label]\n",
    "\n",
    "    # ИСПРАВЛЕНИЕ: передаем cfg в функцию препроцессинга\n",
    "    # Вариант 1: Используем lambda\n",
    "    df['span'] = df['span'].apply(lambda x: clean_text_only(x, cfg))\n",
    "    \n",
    "    # Или Вариант 2: Создаем частично примененную функцию\n",
    "    # clean_text_with_config = partial(clean_text_only, cfg=cfg)\n",
    "    # df['span'] = df['span'].apply(clean_text_with_config)\n",
    "\n",
    "    display(df)\n",
    "\n",
    "    # Сохраняем датасет\n",
    "    df.to_csv(cfg.preprocess.output.dataset_csv, index=False)\n",
    "\n",
    "    mlflow.log_artifact(cfg.preprocess.output.dataset_csv, \"datasets\")\n",
    "\n",
    "    # ИСПРАВЛЕНИЕ: сохраняем функцию с привязанным конфигом\n",
    "    # Создаем частично примененную функцию для сохранения\n",
    "    clean_text_with_config = partial(clean_text_only, cfg=cfg)\n",
    "    with open(cfg.preprocess.output.preprocess_pickle, \"wb\") as f:\n",
    "        cloudpickle.dump(clean_text_with_config, f)\n",
    "\n",
    "    mlflow.log_artifact(cfg.preprocess.output.preprocess_pickle, \"functions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0766fa",
   "metadata": {},
   "source": [
    "## Третий эксперимент (Аугментация данных для минорных классов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b861f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Third dataset\"):\n",
    "\n",
    "    cfg = load_config(\"preprocess_third\")\n",
    "\n",
    "    mlflow.set_tag(\"Dataset_version\", cfg.mlflow.dataset_version)\n",
    "\n",
    "\n",
    "    annotation_dfs = [pd.read_json(path) for path in cfg.preprocess.input_files]\n",
    "    df_annotations = pd.concat(annotation_dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"span\", \"label\"])\n",
    "\n",
    "    for mark in df_annotations['aspect_sentiment']:\n",
    "        for entry in mark:\n",
    "            span = entry['text']\n",
    "            label = entry['labels'][0]\n",
    "            df.loc[len(df)] = [span, label]\n",
    "\n",
    "\n",
    "    class_counts = df['label'].value_counts()\n",
    "    minority_classes = class_counts[class_counts < class_counts.mean()].index.tolist()\n",
    "\n",
    "    print(f\"Minority classes: {minority_classes}\")\n",
    "\n",
    "\n",
    "    import random\n",
    "\n",
    "    synonyms = cfg.preprocess.augmentation.synonyms\n",
    "    n_variants = cfg.preprocess.augmentation.n_variants\n",
    "\n",
    "    def simple_augmentation(text):\n",
    "        augmented = []\n",
    "        for _ in range(n_variants):\n",
    "            words = text.split()\n",
    "            new_words = []\n",
    "            for w in words:\n",
    "                wl = w.lower()\n",
    "                if wl in synonyms and random.random() > 0.7:\n",
    "                    new_words.append(random.choice(synonyms[wl]))\n",
    "                else:\n",
    "                    new_words.append(w)\n",
    "            augmented.append(\" \".join(new_words))\n",
    "        return augmented\n",
    "\n",
    "\n",
    "    augmented_data = []\n",
    "    for label in minority_classes:\n",
    "        samples = df[df['label'] == label]\n",
    "        for _, row in samples.iterrows():\n",
    "            for aug_text in simple_augmentation(row[\"span\"]):\n",
    "                augmented_data.append({\"span\": aug_text, \"label\": label})\n",
    "\n",
    "    df_augmented = pd.DataFrame(augmented_data)\n",
    "\n",
    "\n",
    "    df_extended = pd.concat([df, df_augmented], ignore_index=True)\n",
    "\n",
    "\n",
    "    output_path = cfg.preprocess.output.dataset_csv\n",
    "    df_extended.to_csv(output_path, index=False)\n",
    "\n",
    "    mlflow.log_artifact(output_path, \"datasets\")\n",
    "\n",
    "    print(f\"Сохранен датасет с аугментацией: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790af86c",
   "metadata": {},
   "source": [
    "# Эксперементирование с моделями"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b384f",
   "metadata": {},
   "source": [
    "## Первый эксперимент (Простая модель)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b793612b",
   "metadata": {},
   "source": [
    "Будем обучать простую модель: \"Наивный Байесовский Классификатор\" из `Sklearn`, будем проводить тест на 3 версиях датасета и поймем, какая модель лучше себя покажет при работе с тем или иным датасетом"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead861b4",
   "metadata": {},
   "source": [
    "### Первый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e81f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"naive_bayes_first\")\n",
    "\n",
    "with mlflow.start_run(run_name='first_model_experiment'):\n",
    "\n",
    "    mlflow.set_tag('NaiveBayes', cfg.model.version)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         СЧИТЫВАНИЕ ДАТАСЕТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    client = MlflowClient()\n",
    "\n",
    "    dataset_runs = client.search_runs(\n",
    "        experiment_ids=[cfg.mlflow.experiment_id],\n",
    "        filter_string=f\"tags.mlflow.runName = '{cfg.data.source_run}'\",\n",
    "        order_by=['attributes.end_time desc']\n",
    "    )\n",
    "\n",
    "    first_dataset_latest_run = dataset_runs[0]\n",
    "    first_dataset_latest_run_id = first_dataset_latest_run.info.run_id\n",
    "\n",
    "    # Используем пути из конфига\n",
    "    full_dataset_path = f\"{cfg.data.dataset_path}/{cfg.data.dataset_file}\"\n",
    "    \n",
    "    try:\n",
    "        dataframe_path = client.download_artifacts(first_dataset_latest_run_id, full_dataset_path)\n",
    "        df = pd.read_csv(dataframe_path)\n",
    "        print(f\"✅ Успешно загружен: {full_dataset_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Не удалось загрузить {full_dataset_path}: {e}\")\n",
    "\n",
    "        try:\n",
    "            dataframe_path = client.download_artifacts(first_dataset_latest_run_id, cfg.data.dataset_file)\n",
    "            df = pd.read_csv(dataframe_path)\n",
    "            print(f\"✅ Успешно загружен: {cfg.data.dataset_file}\")\n",
    "        except:\n",
    "            raise ValueError(f\"Не удалось загрузить датасет: {full_dataset_path}\")\n",
    "    \n",
    "    display(df)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                              ВЕКТОРИЗАЦИЯ ТЕКСТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        lowercase=cfg.vectorizer.lowercase,\n",
    "        analyzer=cfg.vectorizer.analyzer,\n",
    "        max_features=cfg.vectorizer.max_features,\n",
    "        ngram_range=tuple(cfg.vectorizer.ngram_range),\n",
    "        min_df=cfg.vectorizer.min_df,\n",
    "        max_df=cfg.vectorizer.max_df\n",
    "    )\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         РАЗБИЕНИЕ НА TRAIN/TEST\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    df_train, df_test = train_test_split(\n",
    "        df, \n",
    "        test_size=cfg.training.test_size, \n",
    "        random_state=cfg.training.random_state, \n",
    "        stratify=df['label']\n",
    "    )\n",
    "\n",
    "    X_train = df_train['span']\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "    y_train = df_train['label']\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "\n",
    "    X_test = df_test['span']\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    y_test = df_test['label']\n",
    "    y_test = encoder.transform(y_test)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ОБУЧЕНИЕ И ЛОГИРОВАНИЕ МОДЕЛИ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "\n",
    "    mlflow.sklearn.autolog(disable=True)\n",
    "    \n",
    "    model = MultinomialNB()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f'f1-score равен {f1:.4f}')\n",
    "    print(f'accuracy-score равен {accuracy:.4f}')\n",
    "\n",
    "    # Сохраняем артефакты\n",
    "    joblib.dump(model, cfg.model.artifacts.model)\n",
    "    joblib.dump(vectorizer, cfg.model.artifacts.vectorizer)\n",
    "    joblib.dump(encoder, cfg.model.artifacts.encoder)\n",
    "    \n",
    "    mlflow.log_artifact(cfg.model.artifacts.model, 'models')\n",
    "    mlflow.log_artifact(cfg.model.artifacts.vectorizer, 'models')\n",
    "    mlflow.log_artifact(cfg.model.artifacts.encoder, 'models')\n",
    "    \n",
    "    # Логируем кастомные метрики\n",
    "    mlflow.log_metrics({\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy\n",
    "    })\n",
    "\n",
    "    # Логируем параметры из конфига\n",
    "    mlflow.log_params({\n",
    "        'vectorizer_max_features': cfg.vectorizer.max_features,\n",
    "        'vectorizer_ngram_range': str(cfg.vectorizer.ngram_range),\n",
    "        'test_size': cfg.training.test_size\n",
    "    })\n",
    "\n",
    "    print(\"Модель успешно обучена и залогирована!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5ddbdb",
   "metadata": {},
   "source": [
    "#### Проверка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93388f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем конфиг для инференса\n",
    "cfg_inference = load_config(\"inference_bayes_first\")\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПОЛУЧЕНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "\n",
    "latest_run_model = client.search_runs(\n",
    "    experiment_ids=[cfg_inference.mlflow.experiment_id],\n",
    "    filter_string=f'tags.mlflow.runName = \"{cfg_inference.model.run_name}\"',\n",
    "    order_by=['attributes.end_time desc']\n",
    ")\n",
    "\n",
    "latest_run_model_id = latest_run_model[0].info.run_id\n",
    "print(f\"Run ID модели: {latest_run_model_id}\")\n",
    "\n",
    "\n",
    "vectorizer_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.vectorizer}\"\n",
    "bayes_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.bayes}\" \n",
    "encoder_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.encoder}\"\n",
    "\n",
    "try:\n",
    "    vectorizer_file = client.download_artifacts(latest_run_model_id, vectorizer_path)\n",
    "    bayes_file = client.download_artifacts(latest_run_model_id, bayes_path)\n",
    "    encoder_file = client.download_artifacts(latest_run_model_id, encoder_path)\n",
    "    print(\"✅ Модели успешно загружены\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ошибка загрузки моделей: {e}\")\n",
    "\n",
    "    try:\n",
    "        vectorizer_file = client.download_artifacts(latest_run_model_id, cfg_inference.model.vectorizer)\n",
    "        bayes_file = client.download_artifacts(latest_run_model_id, cfg_inference.model.bayes)\n",
    "        encoder_file = client.download_artifacts(latest_run_model_id, cfg_inference.model.encoder)\n",
    "        print(\"✅ Модели загружены (fallback)\")\n",
    "    except:\n",
    "        raise ValueError(\"Не удалось загрузить модели\")\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПОЛУЧЕНИЕ ФУНКЦИИ ПРЕПРОЦЕССИНГА\n",
    "# ===========================================================================================\n",
    "\n",
    "\n",
    "latest_run_dataset = client.search_runs(\n",
    "    experiment_ids=[cfg_inference.mlflow.experiment_id],\n",
    "    filter_string=f'tags.mlflow.runName = \"{cfg_inference.preprocess.run_name}\"',\n",
    "    order_by=['attributes.end_time desc']\n",
    ")\n",
    "\n",
    "latest_run_dataset_id = latest_run_dataset[0].info.run_id\n",
    "\n",
    "try:\n",
    "    art_loc = client.download_artifacts(latest_run_dataset_id, cfg_inference.preprocess.artifact_path)\n",
    "    print(\"✅ Функция препроцессинга загружена\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ошибка загрузки функции: {e}\")\n",
    "    raise\n",
    "\n",
    "# ===========================================================================================\n",
    "# ЗАГРУЗКА И ИСПОЛЬЗОВАНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "\n",
    "vectorizer = joblib.load(vectorizer_file)\n",
    "bayes = joblib.load(bayes_file)\n",
    "encoder = joblib.load(encoder_file)\n",
    "\n",
    "\n",
    "with open(art_loc, 'rb') as f:\n",
    "    preprocess_func = cloudpickle.load(f)\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПРЕДСКАЗАНИЕ\n",
    "# ===========================================================================================\n",
    "\n",
    "# Используем текст из конфига\n",
    "text = cfg_inference.test_text\n",
    "\n",
    "preprocessed_text = preprocess_func(text)\n",
    "done_text = vectorizer.transform([preprocessed_text])\n",
    "label = bayes.predict(done_text)\n",
    "\n",
    "print('=' * 100)\n",
    "print(f'Исходный текст: \"{text}\"')\n",
    "print(f'Предобработанный текст: \"{preprocessed_text}\"')\n",
    "print(f'Предсказанная метка: {encoder.inverse_transform(label)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a3439a",
   "metadata": {},
   "source": [
    "### Второй датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca78c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = load_config(\"naive_bayes_second\")\n",
    "\n",
    "with mlflow.start_run(run_name='second_model_experiment'):\n",
    "\n",
    "    mlflow.set_tag('NaiveBayes', cfg.model.version)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         СЧИТЫВАНИЕ ДАТАСЕТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    client = MlflowClient()\n",
    "\n",
    "    dataset_runs = client.search_runs(\n",
    "        experiment_ids=[cfg.mlflow.experiment_id],\n",
    "        filter_string=f\"tags.mlflow.runName = '{cfg.data.source_run}'\",\n",
    "        order_by=['attributes.end_time desc']\n",
    "    )\n",
    "\n",
    "    first_dataset_latest_run = dataset_runs[0]\n",
    "    first_dataset_latest_run_id = first_dataset_latest_run.info.run_id\n",
    "\n",
    "\n",
    "    try:\n",
    "        dataframe_path = client.download_artifacts(first_dataset_latest_run_id, \"datasets/second_experiment_dataset.csv\")\n",
    "        df = pd.read_csv(dataframe_path)\n",
    "        print(\"✅ Датасет загружен напрямую\")\n",
    "    except:\n",
    "        try:\n",
    "            files = client.list_artifacts(first_dataset_latest_run_id, cfg.data.dataset_path)\n",
    "            dataframe = files[0].path\n",
    "            dataframe_path = client.download_artifacts(first_dataset_latest_run_id, dataframe)\n",
    "            df = pd.read_csv(dataframe_path)\n",
    "            print(\"✅ Датасет загружен через list_artifacts\")\n",
    "        except:\n",
    "            raise ValueError(\"Не удалось загрузить датасет\")\n",
    "\n",
    "    display(df)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                              ВЕКТОРИЗАЦИЯ ТЕКСТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        lowercase=cfg.vectorizer.lowercase,\n",
    "        analyzer=cfg.vectorizer.analyzer,\n",
    "        max_features=cfg.vectorizer.max_features,\n",
    "        ngram_range=tuple(cfg.vectorizer.ngram_range),\n",
    "        min_df=cfg.vectorizer.min_df,\n",
    "        max_df=cfg.vectorizer.max_df\n",
    "    )\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         РАЗБИЕНИЕ НА TRAIN/TEST\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    df_train, df_test = train_test_split(\n",
    "        df, \n",
    "        test_size=cfg.training.test_size, \n",
    "        random_state=cfg.training.random_state, \n",
    "        stratify=df['label']\n",
    "    )\n",
    "\n",
    "    X_train = df_train['span']\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "    y_train = df_train['label']\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "\n",
    "    X_test = df_test['span']\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    y_test = df_test['label']\n",
    "    y_test = encoder.transform(y_test)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ОБУЧЕНИЕ И ЛОГИРОВАНИЕ МОДЕЛИ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "    model = MultinomialNB()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f'f1-score равен {f1:.4f}')\n",
    "    print(f'accuracy-score равен {accuracy:.4f}')\n",
    "\n",
    "    joblib.dump(model, cfg.model.artifacts.model)\n",
    "    joblib.dump(vectorizer, cfg.model.artifacts.vectorizer)\n",
    "    joblib.dump(encoder, cfg.model.artifacts.encoder)\n",
    "    \n",
    "    mlflow.log_artifact(cfg.model.artifacts.model, 'models')\n",
    "    mlflow.log_artifact(cfg.model.artifacts.vectorizer, 'models')\n",
    "    mlflow.log_artifact(cfg.model.artifacts.encoder, 'models')\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy\n",
    "    })\n",
    "\n",
    "    mlflow.log_params({\n",
    "        'vectorizer_max_features': cfg.vectorizer.max_features,\n",
    "        'vectorizer_ngram_range': str(cfg.vectorizer.ngram_range),\n",
    "        'test_size': cfg.training.test_size\n",
    "    })\n",
    "\n",
    "    print(\"Вторая модель успешно обучена и залогирована!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cfbf25",
   "metadata": {},
   "source": [
    "#### Проверка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f598e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_inference = load_config(\"inference_bayes_second\")\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПОЛУЧЕНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "\n",
    "latest_run_model = client.search_runs(\n",
    "    experiment_ids=[cfg_inference.mlflow.experiment_id],\n",
    "    filter_string=f'tags.mlflow.runName = \"{cfg_inference.model.run_name}\"', \n",
    "    order_by=['attributes.end_time desc']\n",
    ")\n",
    "\n",
    "if not latest_run_model:\n",
    "    raise ValueError(f\"Не найден run: {cfg_inference.model.run_name}\")\n",
    "\n",
    "latest_run_model_id = latest_run_model[0].info.run_id\n",
    "print(f\"Run ID модели: {latest_run_model_id}\")\n",
    "\n",
    "\n",
    "vectorizer_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.vectorizer}\"\n",
    "bayes_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.bayes}\"\n",
    "encoder_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.encoder}\"\n",
    "\n",
    "print(\"Загружаем модели...\")\n",
    "try:\n",
    "    vectorizer_file = client.download_artifacts(latest_run_model_id, vectorizer_path)\n",
    "    bayes_file = client.download_artifacts(latest_run_model_id, bayes_path)\n",
    "    encoder_file = client.download_artifacts(latest_run_model_id, encoder_path)\n",
    "    print(\"✅ Модели успешно загружены\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ошибка загрузки моделей: {e}\")\n",
    "    raise\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПОЛУЧЕНИЕ ФУНКЦИИ ПРЕПРОЦЕССИНГА\n",
    "# ===========================================================================================\n",
    "\n",
    "\n",
    "latest_run_dataset = client.search_runs(\n",
    "    experiment_ids=[cfg_inference.mlflow.experiment_id],\n",
    "    filter_string=f'tags.mlflow.runName = \"{cfg_inference.preprocess.run_name}\"',\n",
    "    order_by=['attributes.end_time desc']\n",
    ")\n",
    "\n",
    "if not latest_run_dataset:\n",
    "    raise ValueError(f\"Не найден run: {cfg_inference.preprocess.run_name}\")\n",
    "\n",
    "latest_run_dataset_id = latest_run_dataset[0].info.run_id\n",
    "\n",
    "print(\"Загружаем функцию препроцессинга...\")\n",
    "try:\n",
    "    art_loc = client.download_artifacts(latest_run_dataset_id, cfg_inference.preprocess.artifact_path)\n",
    "    print(\"✅ Функция препроцессинга загружена\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ошибка загрузки функции: {e}\")\n",
    "    raise\n",
    "\n",
    "# ===========================================================================================\n",
    "# ЗАГРУЗКА И ИСПОЛЬЗОВАНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "print(\"Загружаем модели в память...\")\n",
    "vectorizer = joblib.load(vectorizer_file)\n",
    "bayes = joblib.load(bayes_file)\n",
    "encoder = joblib.load(encoder_file)\n",
    "\n",
    "print(\"Загружаем функцию препроцессинга...\")\n",
    "with open(art_loc, 'rb') as f:\n",
    "    preprocess_func = cloudpickle.load(f)\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПРЕДСКАЗАНИЕ\n",
    "# ===========================================================================================\n",
    "\n",
    "# Используем текст из конфига\n",
    "text = cfg_inference.test_text\n",
    "\n",
    "print(\"Выполняем предсказание...\")\n",
    "preprocessed_text = preprocess_func(text)\n",
    "done_text = vectorizer.transform([preprocessed_text])\n",
    "label = bayes.predict(done_text)\n",
    "\n",
    "print('=' * 100)\n",
    "print(f'Исходный текст: \"{text}\"')\n",
    "print(f'Предобработанный текст: \"{preprocessed_text}\"')\n",
    "print(f'Предсказанная метка: {encoder.inverse_transform(label)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231b62e",
   "metadata": {},
   "source": [
    "### Третий датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d475c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"naive_bayes_third\")\n",
    "\n",
    "with mlflow.start_run(run_name='third_model_experiment'):\n",
    "\n",
    "    mlflow.set_tag('NaiveBayes', cfg.model.version)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         СЧИТЫВАНИЕ ДАТАСЕТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    client = MlflowClient()\n",
    "\n",
    "    dataset_runs = client.search_runs(\n",
    "        experiment_ids=[cfg.mlflow.experiment_id],\n",
    "        filter_string=f\"tags.mlflow.runName = '{cfg.data.source_run}'\",\n",
    "        order_by=['attributes.end_time desc']\n",
    "    )\n",
    "\n",
    "    if not dataset_runs:\n",
    "        raise ValueError(f\"Не найден run: {cfg.data.source_run}\")\n",
    "\n",
    "    dataset_run = dataset_runs[0]\n",
    "    dataset_run_id = dataset_run.info.run_id\n",
    "    print(f\"✅ Найден run с датасетом: {dataset_run_id}\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        dataframe_path = client.download_artifacts(dataset_run_id, f\"datasets/{cfg.data.dataset_file}\")\n",
    "        df = pd.read_csv(dataframe_path)\n",
    "        print(\"✅ Датасет загружен напрямую\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка загрузки: {e}\")\n",
    "        alternative_paths = [\n",
    "            cfg.data.dataset_file,\n",
    "            f\"artifacts/datasets/{cfg.data.dataset_file}\",\n",
    "            \"third_experiment_dataset.csv\"\n",
    "        ]\n",
    "        \n",
    "        for path in alternative_paths:\n",
    "            try:\n",
    "                dataframe_path = client.download_artifacts(dataset_run_id, path)\n",
    "                df = pd.read_csv(dataframe_path)\n",
    "                print(f\"✅ Датасет загружен: {path}\")\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            raise ValueError(\"Не удалось загрузить датасет\")\n",
    "\n",
    "    display(df)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                              ВЕКТОРИЗАЦИЯ ТЕКСТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        lowercase=cfg.vectorizer.lowercase,\n",
    "        analyzer=cfg.vectorizer.analyzer,\n",
    "        max_features=cfg.vectorizer.max_features,\n",
    "        ngram_range=tuple(cfg.vectorizer.ngram_range),\n",
    "        min_df=cfg.vectorizer.min_df,\n",
    "        max_df=cfg.vectorizer.max_df\n",
    "    )\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         РАЗБИЕНИЕ НА TRAIN/TEST\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    df_train, df_test = train_test_split(\n",
    "        df, \n",
    "        test_size=cfg.training.test_size, \n",
    "        random_state=cfg.training.random_state, \n",
    "        stratify=df['label']\n",
    "    )\n",
    "\n",
    "    X_train = df_train['span']\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "    y_train = df_train['label']\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "\n",
    "    X_test = df_test['span']\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "\n",
    "    y_test = df_test['label']\n",
    "    y_test = encoder.transform(y_test)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ОБУЧЕНИЕ И ЛОГИРОВАНИЕ МОДЕЛИ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    mlflow.sklearn.autolog(disable=True)\n",
    "\n",
    "    model = MultinomialNB()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f'f1-score равен {f1:.4f}')\n",
    "    print(f'accuracy-score равен {accuracy:.4f}')\n",
    "\n",
    "    joblib.dump(model, cfg.model.artifacts.model)\n",
    "    joblib.dump(vectorizer, cfg.model.artifacts.vectorizer)\n",
    "    joblib.dump(encoder, cfg.model.artifacts.encoder)\n",
    "    \n",
    "    mlflow.log_artifact(cfg.model.artifacts.model, 'models')\n",
    "    mlflow.log_artifact(cfg.model.artifacts.vectorizer, 'models')\n",
    "    mlflow.log_artifact(cfg.model.artifacts.encoder, 'models')\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        'f1_score': f1,\n",
    "        'accuracy': accuracy\n",
    "    })\n",
    "\n",
    "    mlflow.log_params({\n",
    "        'vectorizer_max_features': cfg.vectorizer.max_features,\n",
    "        'vectorizer_ngram_range': str(cfg.vectorizer.ngram_range),\n",
    "        'test_size': cfg.training.test_size\n",
    "    })\n",
    "\n",
    "    print(\"Третья модель успешно обучена и залогирована!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb20a7ee",
   "metadata": {},
   "source": [
    "#### Проверка результатоы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8890d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg_inference = load_config(\"inference_bayes_third\")\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПОЛУЧЕНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "\n",
    "latest_run_model = client.search_runs(\n",
    "    experiment_ids=[cfg_inference.mlflow.experiment_id],\n",
    "    filter_string=f'tags.mlflow.runName = \"{cfg_inference.model.run_name}\"',\n",
    "    order_by=['attributes.end_time desc']\n",
    ")\n",
    "\n",
    "if not latest_run_model:\n",
    "    raise ValueError(f\"Не найден run: {cfg_inference.model.run_name}\")\n",
    "\n",
    "latest_run_model_id = latest_run_model[0].info.run_id\n",
    "print(f\"Run ID модели: {latest_run_model_id}\")\n",
    "\n",
    "\n",
    "vectorizer_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.vectorizer}\"\n",
    "bayes_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.bayes}\"\n",
    "encoder_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.encoder}\"\n",
    "\n",
    "print(\"Загружаем модели...\")\n",
    "try:\n",
    "    vectorizer_file = client.download_artifacts(latest_run_model_id, vectorizer_path)\n",
    "    bayes_file = client.download_artifacts(latest_run_model_id, bayes_path)\n",
    "    encoder_file = client.download_artifacts(latest_run_model_id, encoder_path)\n",
    "    print(\"✅ Модели успешно загружены\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ошибка загрузки моделей: {e}\")\n",
    "    raise\n",
    "\n",
    "\n",
    "# ===========================================================================================\n",
    "# ЗАГРУЗКА И ИСПОЛЬЗОВАНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "print(\"Загружаем модели в память...\")\n",
    "vectorizer = joblib.load(vectorizer_file)\n",
    "bayes = joblib.load(bayes_file)\n",
    "encoder = joblib.load(encoder_file)\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПРЕДСКАЗАНИЕ\n",
    "# ===========================================================================================\n",
    "\n",
    "# Используем текст из конфига\n",
    "text = cfg_inference.test_text\n",
    "\n",
    "print(\"Выполняем предсказание...\")\n",
    "done_text = vectorizer.transform([text])\n",
    "label = bayes.predict(done_text)\n",
    "\n",
    "print('=' * 100)\n",
    "print(f'Исходный текст: \"{text}\"')\n",
    "print(f'Предобработанный текст: \"{preprocessed_text}\"')\n",
    "print(f'Предсказанная метка: {encoder.inverse_transform(label)[0]}')\n",
    "print('=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5205f87a",
   "metadata": {},
   "source": [
    "### Итог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Версия': ['Версия 1', 'Версия 2', 'Версия 3'],\n",
    "    'F1-Score': [0.363707, 0.344306, 0.344139],\n",
    "    'Accuracy': [0.413043, 0.391304, 0.391304],\n",
    "    'Описание': ['Лемматизация, удаление знаков пунктуации', 'Очистка от знаков препинания и emoji to text', 'Никакой очистки']\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84af634",
   "metadata": {},
   "source": [
    "## Второй эксперимент (Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f2fe0c",
   "metadata": {},
   "source": [
    "### Первый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = load_config(\"neural_network_first\")\n",
    "\n",
    "with mlflow.start_run(run_name='first_experiment_neural_network'):\n",
    "    \n",
    "    mlflow.set_tag('LSTM', cfg.model.version)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         СЧИТЫВАНИЕ ДАТАСЕТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    client = MlflowClient()\n",
    "\n",
    "    dataset_runs = client.search_runs(\n",
    "        experiment_ids=[cfg.mlflow.experiment_id],\n",
    "        filter_string=f\"tags.mlflow.runName = '{cfg.data.source_run}'\",\n",
    "        order_by=['attributes.end_time desc']\n",
    "    )\n",
    "\n",
    "    if not dataset_runs:\n",
    "        raise ValueError(f\"Не найден run: {cfg.data.source_run}\")\n",
    "\n",
    "    dataset_run = dataset_runs[0]\n",
    "    dataset_run_id = dataset_run.info.run_id\n",
    "    print(f\"✅ Найден run с датасетом: {dataset_run_id}\")\n",
    "\n",
    "    try:\n",
    "        dataframe_path = client.download_artifacts(dataset_run_id, f\"{cfg.data.dataset_path}/{cfg.data.dataset_file}\")\n",
    "        df = pd.read_csv(dataframe_path)\n",
    "        print(\"✅ Датасет загружен напрямую\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка загрузки: {e}\")\n",
    "        try:\n",
    "            files = client.list_artifacts(dataset_run_id, cfg.data.dataset_path)\n",
    "            dataframe = files[0].path\n",
    "            dataframe_path = client.download_artifacts(dataset_run_id, dataframe)\n",
    "            df = pd.read_csv(dataframe_path)\n",
    "            print(\"✅ Датасет загружен через list_artifacts\")\n",
    "        except Exception as e2:\n",
    "            print(f\"❌ Ошибка загрузки через list_artifacts: {e2}\")\n",
    "            alternative_paths = [\n",
    "                cfg.data.dataset_file,\n",
    "                f\"artifacts/{cfg.data.dataset_path}/{cfg.data.dataset_file}\",\n",
    "                \"First_version.csv\"\n",
    "            ]\n",
    "            \n",
    "            for path in alternative_paths:\n",
    "                try:\n",
    "                    dataframe_path = client.download_artifacts(dataset_run_id, path)\n",
    "                    df = pd.read_csv(dataframe_path)\n",
    "                    print(f\"✅ Датасет загружен: {path}\")\n",
    "                    break\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                raise ValueError(\"Не удалось загрузить датасет\")\n",
    "\n",
    "    display(df)\n",
    "    \n",
    "    # =====================================================================================================================================\n",
    "    #                                              ВЕКТОРИЗАЦИЯ ТЕКСТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    mlflow.tensorflow.autolog()\n",
    "\n",
    "    tokenizer = Tokenizer(\n",
    "        num_words=cfg.tokenizer.num_words,\n",
    "        oov_token=cfg.tokenizer.oov_token,\n",
    "        filters=cfg.tokenizer.filters,\n",
    "        lower=cfg.tokenizer.lower,\n",
    "        split=cfg.tokenizer.split,\n",
    "        char_level=cfg.tokenizer.char_level\n",
    "    )\n",
    "\n",
    "    tokenizer.fit_on_texts(df['span'])\n",
    "\n",
    "    df_train, df_temp = train_test_split(\n",
    "        df, \n",
    "        test_size=cfg.training.test_size, \n",
    "        random_state=cfg.training.random_state, \n",
    "        stratify=df['label']\n",
    "    )\n",
    "\n",
    "    df_test, df_val = train_test_split(\n",
    "        df_temp, \n",
    "        test_size=cfg.training.val_size, \n",
    "        random_state=cfg.training.random_state, \n",
    "        stratify=df_temp['label']\n",
    "    )\n",
    "\n",
    "    X_train_vec = tokenizer.texts_to_sequences(df_train['span'])\n",
    "    X_test_vec = tokenizer.texts_to_sequences(df_test['span'])\n",
    "    X_val_vec = tokenizer.texts_to_sequences(df_val['span'])\n",
    "\n",
    "    max_len_text = 0\n",
    "    for i in df['span']:\n",
    "        max_len_text = max(max_len_text, len(i.split(' ')))\n",
    "    print(f\"Максимальная длина текста: {max_len_text}\")\n",
    "\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_vec, max_len_text, padding='post', truncating='post')\n",
    "    X_test_pad = pad_sequences(X_test_vec, max_len_text, padding='post', truncating='post')\n",
    "    X_val_pad = pad_sequences(X_val_vec, max_len_text, padding='post', truncating='post')\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                              ПОДГОТОВКА ТАРГЕТОВ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    y_train = encoder.fit_transform(df_train['label'])\n",
    "    y_test = encoder.transform(df_test['label'])\n",
    "    y_val = encoder.transform(df_val['label'])\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                              СОЗДАНИЕ МОДЕЛИ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(\n",
    "        input_dim=cfg.tokenizer.num_words, \n",
    "        output_dim=cfg.model.embedding_dim, \n",
    "        input_length=max_len_text\n",
    "    ))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(\n",
    "        cfg.model.lstm_units, \n",
    "        dropout=0.2, \n",
    "        recurrent_dropout=0.3\n",
    "    )))\n",
    "\n",
    "    model.add(Dropout(cfg.model.dropout_rate))\n",
    "\n",
    "    model.add(Dense(cfg.model.dense_units, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam', \n",
    "        loss='sparse_categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_pad, \n",
    "        y_train, \n",
    "        batch_size=cfg.training.batch_size, \n",
    "        epochs=cfg.training.epochs, \n",
    "        validation_data=(X_val_pad, y_val)\n",
    "    )\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_pad, y_test)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ЛОГИРОВАНИЕ МОДЕЛИ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    pred_proba = model.predict(X_test_pad)\n",
    "    pred_class = np.argmax(pred_proba, axis=1)\n",
    "    \n",
    "    f1 = f1_score(pred_class, y_test, average='weighted')\n",
    "    accuracy = accuracy_score(pred_class, y_test)\n",
    "\n",
    "    print(f'f1-score у модели равен {f1:.4f}')\n",
    "    print(f'accuracy у модели равен {accuracy:.4f}')\n",
    "\n",
    "    mlflow.log_metric('f1_score', f1)\n",
    "    mlflow.log_metric('accuracy', accuracy)\n",
    "    mlflow.log_metric('test_accuracy', test_accuracy)\n",
    "    mlflow.log_metric('test_loss', test_loss)\n",
    "\n",
    "    model.save(\"LSTM_ver_1.keras\")\n",
    "\n",
    "    with open(cfg.model.artifacts.tokenizer, 'wb') as f:\n",
    "        cloudpickle.dump(tokenizer, f)\n",
    "    \n",
    "    with open(cfg.model.artifacts.encoder, 'wb') as f:\n",
    "        cloudpickle.dump(encoder, f)\n",
    "\n",
    "    mlflow.log_artifact(cfg.model.artifacts.model, 'models')\n",
    "    mlflow.log_artifact(cfg.model.artifacts.tokenizer, 'models') \n",
    "    mlflow.log_artifact(cfg.model.artifacts.encoder, 'models')\n",
    "\n",
    "    mlflow.log_params({\n",
    "        'num_words': cfg.tokenizer.num_words,\n",
    "        'embedding_dim': cfg.model.embedding_dim,\n",
    "        'lstm_units': cfg.model.lstm_units,\n",
    "        'dropout_rate': cfg.model.dropout_rate,\n",
    "        'batch_size': cfg.training.batch_size,\n",
    "        'epochs': cfg.training.epochs\n",
    "    })\n",
    "\n",
    "    print(\"✅ Нейронная сеть успешно обучена и залогирована!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185ff08f",
   "metadata": {},
   "source": [
    "#### Проверка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8881a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_inference = load_config(\"inference_neural_network\")\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПОЛУЧЕНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "latest_run_model = client.search_runs(\n",
    "    experiment_ids=[cfg_inference.mlflow.experiment_id],\n",
    "    filter_string=f'tags.mlflow.runName = \"{cfg_inference.model.run_name}\"',\n",
    "    order_by=['attributes.end_time desc']\n",
    ")\n",
    "\n",
    "if not latest_run_model:\n",
    "    raise ValueError(f\"Не найден run: {cfg_inference.model.run_name}\")\n",
    "\n",
    "latest_run_model_id = latest_run_model[0].info.run_id\n",
    "print(f\"Run ID модели: {latest_run_model_id}\")\n",
    "\n",
    "model_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.model_file}\"\n",
    "tokenizer_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.tokenizer}\"\n",
    "encoder_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.encoder}\"\n",
    "\n",
    "print(\"Загружаем модели...\")\n",
    "try:\n",
    "    model_file = client.download_artifacts(latest_run_model_id, model_path)\n",
    "    tokenizer_file = client.download_artifacts(latest_run_model_id, tokenizer_path)\n",
    "    encoder_file = client.download_artifacts(latest_run_model_id, encoder_path)\n",
    "    print(\"✅ Модели успешно загружены\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ошибка загрузки моделей: {e}\")\n",
    "    raise\n",
    "\n",
    "# ===========================================================================================\n",
    "# ЗАГРУЗКА И ИСПОЛЬЗОВАНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "print(\"Загружаем модели в память...\")\n",
    "model_keras = tf.keras.models.load_model(model_file)\n",
    "encoder = joblib.load(encoder_file)\n",
    "tokenizer = joblib.load(tokenizer_file)\n",
    "\n",
    "print(\"✅ Все модели загружены в память\")\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПРЕДСКАЗАНИЕ\n",
    "# ===========================================================================================\n",
    "\n",
    "text = cfg_inference.test_text\n",
    "\n",
    "print(\"Выполняем предсказание...\")\n",
    "\n",
    "tokenized_text = tokenizer.texts_to_sequences([text])\n",
    "\n",
    "max_len = model_keras.input_shape[1]\n",
    "print(f\"Максимальная длина последовательности: {max_len}\")\n",
    "\n",
    "padded_text = pad_sequences(tokenized_text, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "pred = model_keras.predict(padded_text)\n",
    "\n",
    "predicted_class_ind = np.argmax(pred, axis=1)\n",
    "predicted_class = encoder.inverse_transform(predicted_class_ind)\n",
    "\n",
    "print('=' * 100)\n",
    "print(f'Исходный текст: \"{text}\"')\n",
    "print(f'Предсказанная метка: {predicted_class[0]}')\n",
    "print(f'Вероятности по классам:')\n",
    "for i, prob in enumerate(pred[0]):\n",
    "    class_name = encoder.inverse_transform([i])[0]\n",
    "    print(f'  {class_name}: {prob:.4f}')\n",
    "print('=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d0476",
   "metadata": {},
   "source": [
    "### Второй датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c3bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg = load_config(\"neural_network_second\")\n",
    "\n",
    "with mlflow.start_run(run_name='second_experiment_neural_network'):\n",
    "    \n",
    "    mlflow.set_tag('CNN', cfg.model.version)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         СЧИТЫВАНИЕ ДАТАСЕТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    client = MlflowClient()\n",
    "\n",
    "    dataset_runs = client.search_runs(\n",
    "        experiment_ids=[cfg.mlflow.experiment_id],\n",
    "        filter_string=f\"tags.mlflow.runName = '{cfg.data.source_run}'\",\n",
    "        order_by=['attributes.end_time desc']\n",
    "    )\n",
    "\n",
    "    if not dataset_runs:\n",
    "        raise ValueError(f\"Не найден run: {cfg.data.source_run}\")\n",
    "\n",
    "    dataset_run = dataset_runs[0]\n",
    "    dataset_run_id = dataset_run.info.run_id\n",
    "    print(f\"✅ Найден run с датасетом: {dataset_run_id}\")\n",
    "\n",
    "    try:\n",
    "        dataset_path = f\"{cfg.data.dataset_path}/{cfg.data.dataset_file}\"\n",
    "        art = client.download_artifacts(dataset_run_id, dataset_path)\n",
    "        df = pd.read_csv(art)\n",
    "        print(f\"✅ Датасет загружен: {dataset_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка загрузки: {e}\")\n",
    "        alternative_paths = [\n",
    "            cfg.data.dataset_file,\n",
    "            f\"artifacts/{cfg.data.dataset_path}/{cfg.data.dataset_file}\",\n",
    "            \"Second_version.csv\"\n",
    "        ]\n",
    "        \n",
    "        for path in alternative_paths:\n",
    "            try:\n",
    "                art = client.download_artifacts(dataset_run_id, path)\n",
    "                df = pd.read_csv(art)\n",
    "                print(f\"✅ Датасет загружен: {path}\")\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            raise ValueError(\"Не удалось загрузить датасет\")\n",
    "\n",
    "    display(df)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ТОКЕНИЗАЦИЯ ТЕКСТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    mlflow.tensorflow.autolog()\n",
    "\n",
    "    tokenizer_config = {k: v for k, v in cfg.tokenizer.items() if v is not None}\n",
    "    tokenizer = Tokenizer(**tokenizer_config)\n",
    "    \n",
    "    tokenizer.fit_on_texts(df['span'])\n",
    "\n",
    "    df_train, df_temp = train_test_split(\n",
    "        df, \n",
    "        test_size=cfg.training.test_size, \n",
    "        random_state=cfg.training.random_state\n",
    "    )\n",
    "    \n",
    "    df_test, df_val = train_test_split(\n",
    "        df_temp, \n",
    "        test_size=cfg.training.val_size, \n",
    "        random_state=cfg.training.random_state\n",
    "    )\n",
    "\n",
    "    X_train_vec = tokenizer.texts_to_sequences(df_train['span'])\n",
    "    X_test_vec = tokenizer.texts_to_sequences(df_test['span'])\n",
    "    X_val_vec = tokenizer.texts_to_sequences(df_val['span'])\n",
    "\n",
    "    X_train_pad = pad_sequences(X_train_vec, maxlen=cfg.training.max_sequence_length, padding='post', truncating='post')\n",
    "    X_test_pad = pad_sequences(X_test_vec, maxlen=cfg.training.max_sequence_length, padding='post', truncating='post')\n",
    "    X_val_pad = pad_sequences(X_val_vec, maxlen=cfg.training.max_sequence_length, padding='post', truncating='post')\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ПОДГОТОВКА ТАРГЕТОВ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    y_train = encoder.fit_transform(df_train['label'])\n",
    "    y_test = encoder.transform(df_test['label'])\n",
    "    y_val = encoder.transform(df_val['label'])\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         СОЗДАНИЕ МОДЕЛИ CNN\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Embedding слой\n",
    "    model.add(Embedding(\n",
    "        input_dim=cfg.tokenizer.num_words, \n",
    "        output_dim=cfg.model.embedding_dim, \n",
    "        input_length=cfg.training.max_sequence_length\n",
    "    ))\n",
    "\n",
    "    # Conv1D слой\n",
    "    model.add(Conv1D(\n",
    "        filters=cfg.model.conv_filters,\n",
    "        kernel_size=cfg.model.conv_kernel_size,\n",
    "        activation=cfg.model.conv_activation\n",
    "    ))\n",
    "\n",
    "    model.add(Dropout(cfg.model.dropout_rate_1))\n",
    "\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "\n",
    "    model.add(Dense(cfg.model.dense_units_1, activation=cfg.model.dense_activation_1))\n",
    "\n",
    "    model.add(Dropout(cfg.model.dropout_rate_2))\n",
    "\n",
    "    model.add(Dense(cfg.model.dense_units_2, activation=cfg.model.dense_activation_2))\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", \n",
    "        optimizer='adam', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_pad, \n",
    "        y_train, \n",
    "        batch_size=cfg.training.batch_size, \n",
    "        epochs=cfg.training.epochs, \n",
    "        validation_data=(X_val_pad, y_val)\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    test_loss, test_accuracy = model.evaluate(X_test_pad, y_test)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ЛОГИРОВАНИЕ МОДЕЛИ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    pred = model.predict(X_test_pad)\n",
    "    pred_class = np.argmax(pred, axis=1)\n",
    "\n",
    "    f1 = f1_score(pred_class, y_test, average='weighted')\n",
    "    accuracy = accuracy_score(pred_class, y_test)\n",
    "\n",
    "    print(f'f1-score у модели равен {f1:.4f}')\n",
    "    print(f'accuracy у модели равен {accuracy:.4f}')\n",
    "\n",
    "    mlflow.log_metric('f1_score', f1)\n",
    "    mlflow.log_metric('accuracy', accuracy)\n",
    "    mlflow.log_metric('test_accuracy', test_accuracy)\n",
    "    mlflow.log_metric('test_loss', test_loss)\n",
    "\n",
    "    model.save(cfg.model.artifacts.model)\n",
    "\n",
    "    joblib.dump(tokenizer, cfg.model.artifacts.tokenizer)\n",
    "    joblib.dump(encoder, cfg.model.artifacts.encoder)\n",
    "\n",
    "    mlflow.log_artifact(cfg.model.artifacts.model, 'models')\n",
    "    mlflow.log_artifact(cfg.model.artifacts.tokenizer, 'models')\n",
    "    mlflow.log_artifact(cfg.model.artifacts.encoder, 'models')\n",
    "\n",
    "    mlflow.log_params({\n",
    "        'num_words': cfg.tokenizer.num_words,\n",
    "        'embedding_dim': cfg.model.embedding_dim,\n",
    "        'conv_filters': cfg.model.conv_filters,\n",
    "        'conv_kernel_size': cfg.model.conv_kernel_size,\n",
    "        'dropout_rate_1': cfg.model.dropout_rate_1,\n",
    "        'dropout_rate_2': cfg.model.dropout_rate_2,\n",
    "        'dense_units_1': cfg.model.dense_units_1,\n",
    "        'batch_size': cfg.training.batch_size,\n",
    "        'epochs': cfg.training.epochs,\n",
    "        'max_sequence_length': cfg.training.max_sequence_length\n",
    "    })\n",
    "\n",
    "    print(\"✅ CNN модель успешно обучена и залогирована!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822d25bc",
   "metadata": {},
   "source": [
    "#### Проверка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011461e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_inference = load_config(\"inference_neural_network_second\")\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПОЛУЧЕНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "latest_run_model = client.search_runs(\n",
    "    experiment_ids=[cfg_inference.mlflow.experiment_id],\n",
    "    filter_string=f'tags.mlflow.runName = \"{cfg_inference.model.run_name}\"',\n",
    "    order_by=['attributes.end_time desc']\n",
    ")\n",
    "\n",
    "if not latest_run_model:\n",
    "    raise ValueError(f\"Не найден run: {cfg_inference.model.run_name}\")\n",
    "\n",
    "latest_run_model_id = latest_run_model[0].info.run_id\n",
    "print(f\"Run ID модели: {latest_run_model_id}\")\n",
    "\n",
    "model_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.model_file}\"\n",
    "tokenizer_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.tokenizer}\"\n",
    "encoder_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.encoder}\"\n",
    "\n",
    "print(\"Загружаем модели...\")\n",
    "try:\n",
    "    model_file = client.download_artifacts(latest_run_model_id, model_path)\n",
    "    tokenizer_file = client.download_artifacts(latest_run_model_id, tokenizer_path)\n",
    "    encoder_file = client.download_artifacts(latest_run_model_id, encoder_path)\n",
    "    print(\"✅ Модели успешно загружены\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ошибка загрузки моделей: {e}\")\n",
    "    raise\n",
    "\n",
    "# ===========================================================================================\n",
    "# ЗАГРУЗКА И ИСПОЛЬЗОВАНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "print(\"Загружаем модели в память...\")\n",
    "model_keras = tf.keras.models.load_model(model_file)\n",
    "encoder = joblib.load(encoder_file)\n",
    "tokenizer = joblib.load(tokenizer_file)\n",
    "\n",
    "print(\"✅ Все модели загружены в память\")\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПРЕДСКАЗАНИЕ\n",
    "# ===========================================================================================\n",
    "\n",
    "\n",
    "text = cfg_inference.test_text\n",
    "\n",
    "print(\"Выполняем предсказание...\")\n",
    "\n",
    "\n",
    "tokenized_text = tokenizer.texts_to_sequences([text])\n",
    "\n",
    "\n",
    "max_len = model_keras.input_shape[1]\n",
    "print(f\"Максимальная длина последовательности: {max_len}\")\n",
    "\n",
    "\n",
    "padded_text = pad_sequences(tokenized_text, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "\n",
    "pred = model_keras.predict(padded_text)\n",
    "\n",
    "\n",
    "predicted_class_ind = np.argmax(pred, axis=1)\n",
    "predicted_class = encoder.inverse_transform(predicted_class_ind)\n",
    "\n",
    "print('=' * 100)\n",
    "print(f'Исходный текст: \"{text}\"')\n",
    "print(f'Предсказанная метка: {predicted_class[0]}')\n",
    "print(f'Вероятности по классам:')\n",
    "for i, prob in enumerate(pred[0]):\n",
    "    class_name = encoder.inverse_transform([i])[0]\n",
    "    print(f'  {class_name}: {prob:.4f}')\n",
    "print('=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c696649",
   "metadata": {},
   "source": [
    "### Третий датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7613e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"neural_network_third\")\n",
    "\n",
    "with mlflow.start_run(run_name='third_experiment_neural_network'):\n",
    "    \n",
    "    mlflow.set_tag('Bidirectional_GRU', cfg.model.version)\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         СЧИТЫВАНИЕ ДАТАСЕТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    dataset_runs = client.search_runs(\n",
    "        experiment_ids=[cfg.mlflow.experiment_id],\n",
    "        filter_string=f\"tags.mlflow.runName = '{cfg.data.source_run}'\",\n",
    "        order_by=['attributes.end_time desc']\n",
    "    )\n",
    "\n",
    "    if not dataset_runs:\n",
    "        raise ValueError(f\"Не найден run: {cfg.data.source_run}\")\n",
    "\n",
    "    dataset_run = dataset_runs[0]\n",
    "    dataset_run_id = dataset_run.info.run_id\n",
    "    print(f\"✅ Найден run с датасетом: {dataset_run_id}\")\n",
    "\n",
    "    try:\n",
    "        dataset_path = f\"{cfg.data.dataset_path}/{cfg.data.dataset_file}\"\n",
    "        art = client.download_artifacts(dataset_run_id, dataset_path)\n",
    "        df = pd.read_csv(art)\n",
    "        print(f\"✅ Датасет загружен: {dataset_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка загрузки: {e}\")\n",
    "        alternative_paths = [\n",
    "            cfg.data.dataset_file,\n",
    "            f\"artifacts/{cfg.data.dataset_path}/{cfg.data.dataset_file}\",\n",
    "            \"third_experiment_dataset.csv\"\n",
    "        ]\n",
    "        \n",
    "        for path in alternative_paths:\n",
    "            try:\n",
    "                art = client.download_artifacts(dataset_run_id, path)\n",
    "                df = pd.read_csv(art)\n",
    "                print(f\"✅ Датасет загружен: {path}\")\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            raise ValueError(\"Не удалось загрузить датасет\")\n",
    "\n",
    "    display(df.head())\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ТОКЕНИЗАЦИЯ ТЕКСТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    mlflow.tensorflow.autolog()\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    # Создаем токенизатор с параметрами из конфига\n",
    "    tokenizer_config = {k: v for k, v in cfg.tokenizer.items() if v is not None}\n",
    "    tokenizer = Tokenizer(**tokenizer_config)\n",
    "    \n",
    "    tokenizer.fit_on_texts(df['span'])\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(df['span'])\n",
    "\n",
    "    # Автоматическое определение максимальной длины\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "    print(f\"📏 Максимальная длина последовательности: {max_len}\")\n",
    "\n",
    "    X = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ПРЕОБРАЗОВАНИЕ ТАРГЕТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(df['label'])\n",
    "    num_classes = len(encoder.classes_)\n",
    "    \n",
    "    # =====================================================================================================================================\n",
    "    #                                         РАЗДЕЛЕНИЕ НА TRAIN/TEST/VAL\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, \n",
    "        train_size=1-cfg.training.test_size, \n",
    "        random_state=cfg.training.random_state, \n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    X_test, X_val, y_test, y_val = train_test_split(\n",
    "        X_temp, y_temp, \n",
    "        test_size=cfg.training.val_size, \n",
    "        random_state=cfg.training.random_state, \n",
    "        stratify=y_temp\n",
    "    )\n",
    "\n",
    "    print(f\"📊 Размеры данных:\")\n",
    "    print(f\"   Train: {X_train.shape}, {y_train.shape}\")\n",
    "    print(f\"   Test: {X_test.shape}, {y_test.shape}\")\n",
    "    print(f\"   Val: {X_val.shape}, {y_val.shape}\")\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         СОЗДАНИЕ И ОБУЧЕНИЕ МОДЕЛИ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Embedding слой\n",
    "    model.add(Embedding(\n",
    "        input_dim=cfg.tokenizer.num_words, \n",
    "        output_dim=cfg.model.embedding_dim\n",
    "    ))\n",
    "\n",
    "    # Bidirectional GRU слой\n",
    "    model.add(Bidirectional(GRU(cfg.model.gru_units)))\n",
    "\n",
    "    # Dense слои\n",
    "    model.add(Dense(cfg.model.dense_units, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", \n",
    "        optimizer='adam', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Обучение\n",
    "    model.fit(\n",
    "        X_train, y_train, \n",
    "        epochs=cfg.training.epochs, \n",
    "        batch_size=cfg.training.batch_size, \n",
    "        validation_data=(X_val, y_val)\n",
    "    )\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ОЦЕНКА МОДЕЛИ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'📊 Test Loss: {loss:.4f}')\n",
    "    print(f'📊 Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    f1 = f1_score(y_pred, y_test, average='weighted')\n",
    "    acc_score = accuracy_score(y_pred, y_test)\n",
    "\n",
    "    print(f'🎯 F1-score: {f1:.4f}')\n",
    "    print(f'🎯 Accuracy: {acc_score:.4f}')\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ЛОГИРОВАНИЕ МЕТРИК\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    mlflow.log_metric('f1_score', f1)\n",
    "    mlflow.log_metric('accuracy', acc_score)\n",
    "    mlflow.log_metric('test_loss', loss)\n",
    "    mlflow.log_metric('test_accuracy', accuracy)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         СОХРАНЕНИЕ АРТЕФАКТОВ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    # Сохраняем модель\n",
    "    model.save(cfg.model.artifacts.model)\n",
    "    mlflow.log_artifact(cfg.model.artifacts.model, 'models')\n",
    "\n",
    "    # Сохраняем preprocessing объекты\n",
    "    with open(cfg.model.artifacts.tokenizer, 'wb') as f:\n",
    "        pickle.dump(tokenizer, f)\n",
    "    mlflow.log_artifact(cfg.model.artifacts.tokenizer, 'preprocessing')\n",
    "\n",
    "    with open(cfg.model.artifacts.encoder, 'wb') as f:\n",
    "        pickle.dump(encoder, f)\n",
    "    mlflow.log_artifact(cfg.model.artifacts.encoder, 'preprocessing')\n",
    "\n",
    "    # Сохраняем информацию о предобработке\n",
    "    preprocessing_info = {\n",
    "        'vocab_size': len(tokenizer.word_index),\n",
    "        'max_sequence_length': max_len,\n",
    "        'num_classes': num_classes,\n",
    "        'classes': list(encoder.classes_)\n",
    "    }\n",
    "    \n",
    "    with open(cfg.model.artifacts.preprocessing_info, 'wb') as f:\n",
    "        pickle.dump(preprocessing_info, f)\n",
    "    mlflow.log_artifact(cfg.model.artifacts.preprocessing_info, 'preprocessing')\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ЛОГИРОВАНИЕ ПАРАМЕТРОВ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    mlflow.log_params({\n",
    "        \"model_type\": \"Bidirectional_GRU\",\n",
    "        \"embedding_dim\": cfg.model.embedding_dim,\n",
    "        \"gru_units\": cfg.model.gru_units,\n",
    "        \"dense_units\": cfg.model.dense_units,\n",
    "        \"num_classes\": num_classes,\n",
    "        \"vocab_size\": len(tokenizer.word_index),\n",
    "        \"max_sequence_length\": max_len,\n",
    "        \"batch_size\": cfg.training.batch_size,\n",
    "        \"epochs\": cfg.training.epochs\n",
    "    })\n",
    "\n",
    "    print(\"✅ Bidirectional GRU модель успешно обучена и залогирована!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0505cd4d",
   "metadata": {},
   "source": [
    "#### Проверка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ea0dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_inference = load_config(\"inference_neural_network_third\")\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПОЛУЧЕНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "latest_run_model = client.search_runs(\n",
    "    experiment_ids=[cfg_inference.mlflow.experiment_id],\n",
    "    filter_string=f'attributes.run_name = \"{cfg_inference.model.run_name}\"',\n",
    "    order_by=['attributes.end_time desc']\n",
    ")\n",
    "\n",
    "if not latest_run_model:\n",
    "    raise ValueError(f\"Не найден run: {cfg_inference.model.run_name}\")\n",
    "\n",
    "latest_run_model_id = latest_run_model[0].info.run_id\n",
    "print(f\"Run ID модели: {latest_run_model_id}\")\n",
    "\n",
    "# Формируем пути к артефактам\n",
    "model_path = f\"{cfg_inference.model.artifacts_path}/{cfg_inference.model.model_file}\"\n",
    "tokenizer_path = f\"preprocessing/{cfg_inference.model.tokenizer}\"\n",
    "encoder_path = f\"preprocessing/{cfg_inference.model.encoder}\"\n",
    "info_path = f\"preprocessing/{cfg_inference.model.preprocessing_info}\"\n",
    "\n",
    "print(\"Загружаем модели...\")\n",
    "try:\n",
    "    model_file = client.download_artifacts(latest_run_model_id, model_path)\n",
    "    tokenizer_file = client.download_artifacts(latest_run_model_id, tokenizer_path)\n",
    "    encoder_file = client.download_artifacts(latest_run_model_id, encoder_path)\n",
    "    info_file = client.download_artifacts(latest_run_model_id, info_path)\n",
    "    print(\"✅ Все модели успешно загружены\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ошибка загрузки моделей: {e}\")\n",
    "    raise\n",
    "\n",
    "# ===========================================================================================\n",
    "# ЗАГРУЗКА И ИСПОЛЬЗОВАНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "print(\"Загружаем модели в память...\")\n",
    "model_keras = tf.keras.models.load_model(model_file)\n",
    "\n",
    "with open(tokenizer_file, 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "\n",
    "with open(encoder_file, 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "\n",
    "with open(info_file, 'rb') as f:\n",
    "    preprocessing_info = pickle.load(f)\n",
    "\n",
    "print(\"✅ Все модели загружены в память\")\n",
    "print(f\"📊 Информация о предобработке: {preprocessing_info}\")\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПРЕДСКАЗАНИЕ\n",
    "# ===========================================================================================\n",
    "\n",
    "text = cfg_inference.test_text\n",
    "\n",
    "print(\"Выполняем предсказание...\")\n",
    "\n",
    "# Токенизация текста\n",
    "tokenized_text = tokenizer.texts_to_sequences([text])\n",
    "print(f\"Токенизированный текст: {tokenized_text}\")\n",
    "\n",
    "# Получаем максимальную длину последовательности из preprocessing_info\n",
    "max_len = preprocessing_info['max_sequence_length']\n",
    "print(f\"Максимальная длина последовательности: {max_len}\")\n",
    "\n",
    "# Паддинг\n",
    "padded_text = pad_sequences(tokenized_text, maxlen=max_len, padding='post', truncating='post')\n",
    "print(f\"Текст после паддинга: {padded_text}\")\n",
    "\n",
    "# Предсказание\n",
    "pred = model_keras.predict(padded_text)\n",
    "print(f\"Сырые предсказания: {pred}\")\n",
    "\n",
    "# Обработка результатов\n",
    "predicted_class_ind = np.argmax(pred, axis=1)\n",
    "predicted_class = encoder.inverse_transform(predicted_class_ind)\n",
    "confidence = np.max(pred, axis=1)[0]\n",
    "\n",
    "print('=' * 100)\n",
    "print(f'Исходный текст: \"{text}\"')\n",
    "print(f'Предсказанная метка: {predicted_class[0]}')\n",
    "print(f'Уверенность: {confidence:.4f}')\n",
    "print(f'Все вероятности:')\n",
    "for i, prob in enumerate(pred[0]):\n",
    "    class_name = encoder.inverse_transform([i])[0]\n",
    "    print(f'  {class_name}: {prob:.4f}')\n",
    "print('=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e2918",
   "metadata": {},
   "source": [
    "## Третий эксперимент (Трансформеры)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74382c43",
   "metadata": {},
   "source": [
    "### Первый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78383437",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"transformers_first\")\n",
    "\n",
    "with mlflow.start_run(run_name='transformers_experiment_1'):\n",
    "    \n",
    "    mlflow.set_tag('Transformers', cfg.model.version)\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         СЧИТЫВАНИЕ ДАТАСЕТА\n",
    "    # =====================================================================================================================================\n",
    "    \n",
    "\n",
    "    dataset_runs = client.search_runs(\n",
    "        experiment_ids=[cfg.mlflow.experiment_id],\n",
    "        filter_string=f\"tags.mlflow.runName = '{cfg.data.source_run}'\",\n",
    "        order_by=['attributes.end_time desc']\n",
    "    )\n",
    "\n",
    "    if not dataset_runs:\n",
    "        raise ValueError(f\"Не найден run: {cfg.data.source_run}\")\n",
    "\n",
    "    dataset_run = dataset_runs[0]\n",
    "    dataset_run_id = dataset_run.info.run_id\n",
    "    print(f\"✅ Найден run с датасетом: {dataset_run_id}\")\n",
    "\n",
    "\n",
    "    try:\n",
    "        dataset_path = f\"{cfg.data.dataset_path}/{cfg.data.dataset_file}\"\n",
    "        art_loc = client.download_artifacts(dataset_run_id, dataset_path)\n",
    "        df = pd.read_csv(art_loc)\n",
    "        print(f\"✅ Датасет загружен: {dataset_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка загрузки: {e}\")\n",
    "\n",
    "        alternative_paths = [\n",
    "            cfg.data.dataset_file,\n",
    "            f\"artifacts/{cfg.data.dataset_path}/{cfg.data.dataset_file}\",\n",
    "            \"First_version.csv\"\n",
    "        ]\n",
    "        \n",
    "        for path in alternative_paths:\n",
    "            try:\n",
    "                art_loc = client.download_artifacts(dataset_run_id, path)\n",
    "                df = pd.read_csv(art_loc)\n",
    "                print(f\"✅ Датасет загружен: {path}\")\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            raise ValueError(\"Не удалось загрузить датасет\")\n",
    "\n",
    "\n",
    "    df = df[[cfg.data.text_column, cfg.data.label_column]]\n",
    "    df = df.rename(columns={cfg.data.label_column: \"labels\"})\n",
    "    display(df)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ПОДГОТОВКА ДАТАСЕТА/ТАРГЕТОВ\n",
    "    # =====================================================================================================================================\n",
    "    \n",
    "    df_train, df_temp = train_test_split(\n",
    "        df, \n",
    "        test_size=cfg.training.test_size, \n",
    "        random_state=cfg.training.random_state, \n",
    "        stratify=df['labels']\n",
    "    )\n",
    "    \n",
    "    df_test, df_val = train_test_split(\n",
    "        df_temp, \n",
    "        test_size=cfg.training.val_size, \n",
    "        random_state=cfg.training.random_state, \n",
    "        stratify=df_temp['labels']\n",
    "    )\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    y_train = encoder.fit_transform(df_train['labels'])\n",
    "    y_test = encoder.transform(df_test['labels'])\n",
    "    y_val = encoder.transform(df_val['labels'])\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ПОДГОТОВКА МОДЕЛИ\n",
    "    # =====================================================================================================================================\n",
    "    \n",
    "    mlflow.transformers.autolog()\n",
    "\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.model.model_name)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        cfg.model.model_name, \n",
    "        num_labels=len(encoder.classes_), \n",
    "        id2label={i: label for i, label in enumerate(encoder.classes_)},\n",
    "        label2id={label: i for i, label in enumerate(encoder.classes_)}\n",
    "    )\n",
    "    \n",
    "\n",
    "    dataset_train = Dataset.from_pandas(df_train.assign(labels=y_train))    \n",
    "    dataset_test = Dataset.from_pandas(df_test.assign(labels=y_test))    \n",
    "    dataset_val = Dataset.from_pandas(df_val.assign(labels=y_val))\n",
    "\n",
    "\n",
    "    def tokenize_dataset(row):\n",
    "        tokenizer_config = {k: v for k, v in cfg.tokenizer.items() if v is not None}\n",
    "        return tokenizer(row[cfg.data.text_column], **tokenizer_config)\n",
    "\n",
    "    dataset_tokenized_train = dataset_train.map(tokenize_dataset, batched=False)\n",
    "    dataset_tokenized_test = dataset_test.map(tokenize_dataset, batched=False)\n",
    "    dataset_tokenized_val = dataset_val.map(tokenize_dataset, batched=False)\n",
    "\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(\n",
    "        tokenizer=tokenizer,\n",
    "        padding=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=cfg.training.output_dir,\n",
    "        overwrite_output_dir=True,\n",
    "        logging_dir='./logs/',\n",
    "        num_train_epochs=cfg.training.num_train_epochs,\n",
    "        learning_rate=cfg.training.learning_rate,\n",
    "        per_device_train_batch_size=cfg.training.per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=cfg.training.per_device_eval_batch_size,\n",
    "        eval_strategy=cfg.training.eval_strategy,\n",
    "        save_strategy=cfg.training.save_strategy,\n",
    "        warmup_ratio=cfg.training.warmup_ratio,\n",
    "        lr_scheduler_type=cfg.training.lr_scheduler_type,\n",
    "        metric_for_best_model=cfg.training.metric_for_best_model,\n",
    "        weight_decay=cfg.training.weight_decay,\n",
    "        load_best_model_at_end=cfg.training.load_best_model_at_end,\n",
    "        save_total_limit=cfg.training.save_total_limit,\n",
    "        max_grad_norm=cfg.training.max_grad_norm,\n",
    "        logging_steps=cfg.training.logging_steps\n",
    "    )\n",
    "\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "        \n",
    "        return {\n",
    "            'f1-score': f1_score(labels, predictions, average='weighted'),\n",
    "            'accuracy': accuracy_score(labels, predictions)\n",
    "        }\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model, \n",
    "        args=training_args, \n",
    "        train_dataset=dataset_tokenized_train,\n",
    "        eval_dataset=dataset_tokenized_val,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=cfg.training.early_stopping_patience)]\n",
    "    )\n",
    "\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "\n",
    "    final_metrics = trainer.evaluate(dataset_tokenized_test)\n",
    "    print(f\"✅ Финальные метрики: {final_metrics}\")\n",
    "\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         СОХРАНЕНИЕ И ЛОГИРОВАНИЕ МОДЕЛИ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    # Получаем предсказания на тестовом наборе\n",
    "    final_predictions = trainer.predict(dataset_tokenized_test)\n",
    "    predictions = np.argmax(final_predictions.predictions, axis=1)\n",
    "    labels = final_predictions.label_ids\n",
    "\n",
    "    # Вычисляем нужные метрики\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    # Логируем метрики с нужными названиями\n",
    "    mlflow.log_metric('f1_score', f1)\n",
    "    mlflow.log_metric('accuracy', accuracy) \n",
    "    \n",
    "    # Также можно залогировать остальные метрики без префикса eval_\n",
    "    for key, value in final_predictions.metrics.items():\n",
    "        if key.startswith('eval_'):\n",
    "            clean_key = key.replace('eval_', '')\n",
    "            mlflow.log_metric(clean_key, value)\n",
    "\n",
    "    print(f\"✅ Final metrics - F1: {f1:.4f}, Accuracy: {accuracy:.4f}, Loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Сохраняем артефакты\n",
    "    model_dir = cfg.artifacts.model_dir\n",
    "    tokenizer_dir = cfg.artifacts.tokenizer_dir\n",
    "\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(tokenizer_dir, exist_ok=True)\n",
    "\n",
    "    model.save_pretrained(model_dir)\n",
    "    tokenizer.save_pretrained(tokenizer_dir)\n",
    "\n",
    "    mlflow.log_artifacts(model_dir, \"model\")\n",
    "    mlflow.log_artifacts(tokenizer_dir, \"tokenizer\")\n",
    "\n",
    "    with open('label_encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(encoder, f)\n",
    "    mlflow.log_artifact('label_encoder.pkl')\n",
    "\n",
    "    mlflow.log_params({\n",
    "        'model_name': cfg.model.model_name,\n",
    "        'num_labels': len(encoder.classes_),\n",
    "        'num_train_epochs': cfg.training.num_train_epochs,\n",
    "        'learning_rate': cfg.training.learning_rate,\n",
    "        'batch_size': cfg.training.per_device_train_batch_size,\n",
    "        'early_stopping_patience': cfg.training.early_stopping_patience\n",
    "    })\n",
    "\n",
    "    print(\"✅ Трансформер успешно обучен и залогирован!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd1e63",
   "metadata": {},
   "source": [
    "#### Проверка результата"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f288885",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_inference = load_config(\"inference_transformers_first\")\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПОЛУЧЕНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "\n",
    "latest_run_model = client.search_runs(\n",
    "    experiment_ids=[cfg_inference.mlflow.experiment_id],\n",
    "    filter_string=f'tags.mlflow.runName = \"{cfg_inference.model.run_name}\"',\n",
    "    order_by=['attributes.end_time desc']\n",
    ")\n",
    "\n",
    "if not latest_run_model:\n",
    "    raise ValueError(f\"Не найден run: {cfg_inference.model.run_name}\")\n",
    "\n",
    "latest_run_model_id = latest_run_model[0].info.run_id\n",
    "print(f\"Run ID модели: {latest_run_model_id}\")\n",
    "\n",
    "\n",
    "print(\"Загружаем модель и токенизатор...\")\n",
    "try:\n",
    "\n",
    "    model_dir = client.download_artifacts(latest_run_model_id, cfg_inference.model.artifacts_path)\n",
    "    tokenizer_dir = client.download_artifacts(latest_run_model_id, cfg_inference.model.tokenizer_path)\n",
    "    print(\"✅ Модель и токенизатор успешно загружены\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ошибка загрузки моделей: {e}\")\n",
    "    raise\n",
    "\n",
    "# ===========================================================================================\n",
    "# ЗАГРУЗКА И ИСПОЛЬЗОВАНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "print(\"Загружаем модели в память...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_dir)\n",
    "\n",
    "print(\"✅ Модель и токенизатор загружены в память\")\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПРЕДСКАЗАНИЕ\n",
    "# ===========================================================================================\n",
    "\n",
    "\n",
    "text = cfg_inference.test_text\n",
    "\n",
    "print(\"Выполняем предсказание...\")\n",
    "\n",
    "\n",
    "tokenizer_config = {k: v for k, v in cfg_inference.tokenizer.items() if v is not None}\n",
    "inputs = tokenizer(text, **tokenizer_config)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "predicted_class_idx = predictions.argmax().item()\n",
    "predicted_prob = predictions.max().item()\n",
    "\n",
    "id2label = model.config.id2label\n",
    "predicted_label = id2label[predicted_class_idx]\n",
    "\n",
    "print('=' * 100)\n",
    "print(f'Исходный текст: \"{text}\"')\n",
    "print(f'Предсказанная метка: {predicted_label}')\n",
    "print(f'Вероятность: {predicted_prob:.4f}')\n",
    "print(f'Все вероятности:')\n",
    "for i, prob in enumerate(predictions[0]):\n",
    "    label = id2label[i]\n",
    "    print(f'  {label}: {prob:.4f}')\n",
    "print('=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4736547f",
   "metadata": {},
   "source": [
    "### Второй датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150746b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"transformers_second\")\n",
    "\n",
    "with mlflow.start_run(run_name='transformers_experiment_2'):\n",
    "    \n",
    "    mlflow.set_tag('Transformers', cfg.model.version)\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         СЧИТЫВАНИЕ ДАТАСЕТА\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    dataset_runs = client.search_runs(\n",
    "        experiment_ids=[cfg.mlflow.experiment_id],\n",
    "        filter_string=f\"tags.mlflow.runName = '{cfg.data.source_run}'\",\n",
    "        order_by=['attributes.end_time desc']\n",
    "    )\n",
    "\n",
    "    if not dataset_runs:\n",
    "        raise ValueError(f\"Не найден run: {cfg.data.source_run}\")\n",
    "\n",
    "    dataset_run = dataset_runs[0]\n",
    "    dataset_run_id = dataset_run.info.run_id\n",
    "    print(f\"✅ Найден run с датасетом: {dataset_run_id}\")\n",
    "\n",
    "    try:\n",
    "        dataset_path = f\"{cfg.data.dataset_path}/{cfg.data.dataset_file}\"\n",
    "        art_loc = client.download_artifacts(dataset_run_id, dataset_path)\n",
    "        df = pd.read_csv(art_loc)\n",
    "        print(f\"✅ Датасет загружен: {dataset_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ошибка загрузки: {e}\")\n",
    "\n",
    "        alternative_paths = [\n",
    "            cfg.data.dataset_file,\n",
    "            f\"artifacts/{cfg.data.dataset_path}/{cfg.data.dataset_file}\",\n",
    "            \"second_experiment_dataset.csv\"\n",
    "        ]\n",
    "        \n",
    "        for path in alternative_paths:\n",
    "            try:\n",
    "                art_loc = client.download_artifacts(dataset_run_id, path)\n",
    "                df = pd.read_csv(art_loc)\n",
    "                print(f\"✅ Датасет загружен: {path}\")\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            raise ValueError(\"Не удалось загрузить датасет\")\n",
    "\n",
    "    display(df.head())\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ПОДГОТОВКА ДАННЫХ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    encoder = LabelEncoder()\n",
    "    df['label_encoded'] = encoder.fit_transform(df[cfg.data.label_column])\n",
    "    df = df.rename(columns={'label_encoded': 'labels'})\n",
    "    df = df[[cfg.data.text_column, 'labels']]\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ПОДГОТОВКА МОДЕЛИ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    # ВЫКЛЮЧАЕМ autolog - будем логировать вручную для контроля\n",
    "    # mlflow.transformers.autolog()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.model.model_name)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        cfg.model.model_name,\n",
    "        num_labels=len(encoder.classes_),\n",
    "        id2label={i: label for i, label in enumerate(encoder.classes_)},\n",
    "        label2id={label: i for i, label in enumerate(encoder.classes_)}\n",
    "    )\n",
    "    \n",
    "    # =====================================================================================================================================\n",
    "    #                                         РАЗДЕЛЕНИЕ ДАННЫХ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    df_train, df_temp = train_test_split(\n",
    "        df, \n",
    "        train_size=1-cfg.training.test_size, \n",
    "        random_state=cfg.training.random_state, \n",
    "        stratify=df['labels']\n",
    "    )\n",
    "    \n",
    "    df_test, df_val = train_test_split(\n",
    "        df_temp, \n",
    "        test_size=cfg.training.val_size, \n",
    "        random_state=cfg.training.random_state, \n",
    "        stratify=df_temp['labels']\n",
    "    )\n",
    "\n",
    "    # Создаем datasets\n",
    "    dataset_train = Dataset.from_pandas(df_train)\n",
    "    dataset_test = Dataset.from_pandas(df_test)\n",
    "    dataset_val = Dataset.from_pandas(df_val)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ТОКЕНИЗАЦИЯ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    def tokenize_dataset(batch):\n",
    "        tokenizer_config = {k: v for k, v in cfg.tokenizer.items() if v is not None}\n",
    "        return tokenizer(\n",
    "            batch[cfg.data.text_column],\n",
    "            **tokenizer_config\n",
    "        )\n",
    "\n",
    "    tokenized_train = dataset_train.map(tokenize_dataset, batched=True)\n",
    "    tokenized_test = dataset_test.map(tokenize_dataset, batched=True)\n",
    "    tokenized_val = dataset_val.map(tokenize_dataset, batched=True)\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         DATA COLLATOR\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    data_collator = DataCollatorWithPadding(\n",
    "        tokenizer=tokenizer,\n",
    "        padding=True,\n",
    "        max_length=cfg.tokenizer.max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         TRAINING ARGUMENTS\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=cfg.training.output_dir,\n",
    "        num_train_epochs=cfg.training.num_train_epochs,\n",
    "        learning_rate=cfg.training.learning_rate,\n",
    "        per_device_train_batch_size=cfg.training.per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=cfg.training.per_device_eval_batch_size,\n",
    "        eval_strategy=cfg.training.eval_strategy,\n",
    "        save_strategy=cfg.training.save_strategy,\n",
    "        logging_dir=cfg.training.logging_dir,\n",
    "        logging_steps=cfg.training.logging_steps,\n",
    "        load_best_model_at_end=cfg.training.load_best_model_at_end,\n",
    "        metric_for_best_model=cfg.training.metric_for_best_model\n",
    "    )\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         МЕТРИКИ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "        return {\n",
    "            'f1_score': f1_score(y_pred, labels, average='weighted'),\n",
    "            'accuracy': accuracy_score(y_pred, labels)\n",
    "        }\n",
    "    \n",
    "    # =====================================================================================================================================\n",
    "    #                                         TRAINER И ОБУЧЕНИЕ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    # Обучение\n",
    "    trainer.train()\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ОЦЕНКА И ЛОГИРОВАНИЕ МЕТРИК\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    # Получаем предсказания для вычисления метрик\n",
    "    test_predictions = trainer.predict(tokenized_test)\n",
    "    test_preds = np.argmax(test_predictions.predictions, axis=1)\n",
    "    test_labels = test_predictions.label_ids\n",
    "\n",
    "    # ВЫЧИСЛЯЕМ МЕТРИКИ ВРУЧНУЮ с нужными названиями\n",
    "    accuracy = accuracy_score(test_labels, test_preds)\n",
    "    f1_score_value = f1_score(test_labels, test_preds, average='weighted')\n",
    "\n",
    "    # ЛОГИРУЕМ МЕТРИКИ с точными названиями\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"f1_score\", f1_score_value)\n",
    "\n",
    "    print(f\"🎯 Финальные метрики:\")\n",
    "    print(f\"   accuracy: {accuracy:.4f}\")\n",
    "    print(f\"   f1_score: {f1_score_value:.4f}\")\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         СОХРАНЕНИЕ АРТЕФАКТОВ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    # Создаем временные папки для артефактов\n",
    "    model_dir = cfg.artifacts.model_dir\n",
    "    tokenizer_dir = cfg.artifacts.tokenizer_dir\n",
    "    \n",
    "    # Очищаем папки если существуют\n",
    "    import shutil\n",
    "    if os.path.exists(model_dir):\n",
    "        shutil.rmtree(model_dir)\n",
    "    if os.path.exists(tokenizer_dir):\n",
    "        shutil.rmtree(tokenizer_dir)\n",
    "\n",
    "    # Сохраняем модель и токенизатор\n",
    "    trainer.save_model(model_dir)\n",
    "    tokenizer.save_pretrained(tokenizer_dir)\n",
    "\n",
    "    # Сохраняем encoder\n",
    "    with open('label_encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(encoder, f)\n",
    "\n",
    "    # ЛОГИРУЕМ АРТЕФАКТЫ в нужной структуре\n",
    "    mlflow.log_artifacts(model_dir, \"model\")\n",
    "    mlflow.log_artifacts(tokenizer_dir, \"tokenizer\")\n",
    "    mlflow.log_artifact('label_encoder.pkl')\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ЛОГИРОВАНИЕ ПАРАМЕТРОВ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    mlflow.log_params({\n",
    "        'model_name': cfg.model.model_name,\n",
    "        'num_labels': len(encoder.classes_),\n",
    "        'num_train_epochs': cfg.training.num_train_epochs,\n",
    "        'learning_rate': cfg.training.learning_rate,\n",
    "        'batch_size': cfg.training.per_device_train_batch_size,\n",
    "        'test_size': cfg.training.test_size,\n",
    "        'val_size': cfg.training.val_size\n",
    "    })\n",
    "\n",
    "    # =====================================================================================================================================\n",
    "    #                                         ОЧИСТКА ВРЕМЕННЫХ ФАЙЛОВ\n",
    "    # =====================================================================================================================================\n",
    "\n",
    "    shutil.rmtree(model_dir)\n",
    "    shutil.rmtree(tokenizer_dir)\n",
    "    os.remove('label_encoder.pkl')\n",
    "\n",
    "    print(\"✅ Трансформер успешно обучен и залогирован!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959aa2cd",
   "metadata": {},
   "source": [
    "#### Проверка результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdc529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_inference = load_config(\"inference_transformers_second\")\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПОЛУЧЕНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "latest_run_model = client.search_runs(\n",
    "    experiment_ids=[cfg_inference.mlflow.experiment_id],\n",
    "    filter_string=f'attributes.run_name = \"{cfg_inference.model.run_name}\"',\n",
    "    order_by=['attributes.end_time desc']\n",
    ")\n",
    "\n",
    "if not latest_run_model:\n",
    "    raise ValueError(f\"Не найден run: {cfg_inference.model.run_name}\")\n",
    "\n",
    "latest_run_model_id = latest_run_model[0].info.run_id\n",
    "print(f\"Run ID модели: {latest_run_model_id}\")\n",
    "\n",
    "print(\"Загружаем модель, токенизатор и энкодер...\")\n",
    "try:\n",
    "    model_dir = client.download_artifacts(latest_run_model_id, 'model')\n",
    "    tokenizer_dir = client.download_artifacts(latest_run_model_id, 'tokenizer')\n",
    "    encoder_path = client.download_artifacts(latest_run_model_id, 'label_encoder.pkl')\n",
    "    print(\"✅ Модель, токенизатор и энкодер успешно загружены\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ошибка загрузки: {e}\")\n",
    "    raise\n",
    "\n",
    "# ===========================================================================================\n",
    "# ЗАГРУЗКА И ИСПОЛЬЗОВАНИЕ МОДЕЛЕЙ\n",
    "# ===========================================================================================\n",
    "\n",
    "print(\"Загружаем модели в память...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_dir)\n",
    "\n",
    "# Загружаем encoder\n",
    "with open(encoder_path, 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "\n",
    "print(\"✅ Модель, токенизатор и энкодер загружены в память\")\n",
    "\n",
    "# ===========================================================================================\n",
    "# ПРЕДСКАЗАНИЕ\n",
    "# ===========================================================================================\n",
    "\n",
    "text = cfg_inference.test_text\n",
    "\n",
    "print(\"Выполняем предсказание...\")\n",
    "\n",
    "# Конфиг токенизатора из конфига\n",
    "tokenizer_config = {k: v for k, v in cfg_inference.tokenizer.items() if v is not None}\n",
    "inputs = tokenizer(text, **tokenizer_config)\n",
    "\n",
    "# Предсказание\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "predicted_class_idx = predictions.argmax().item()\n",
    "predicted_prob = predictions.max().item()\n",
    "\n",
    "# Используем encoder для получения оригинального названия класса\n",
    "predicted_label = encoder.inverse_transform([predicted_class_idx])[0]\n",
    "\n",
    "print('=' * 100)\n",
    "print(f'Исходный текст: \"{text}\"')\n",
    "print(f'Предсказанная метка: {predicted_label}')\n",
    "print(f'Вероятность: {predicted_prob:.4f}')\n",
    "print(f'Все вероятности:')\n",
    "for i, prob in enumerate(predictions[0]):\n",
    "    label = encoder.inverse_transform([i])[0]\n",
    "    print(f'  {label}: {prob:.4f}')\n",
    "print('=' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7429c5",
   "metadata": {},
   "source": [
    "### Третий датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd76d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"transformers_third\")\n",
    "\n",
    "with mlflow.start_run(run_name=cfg.mlflow.run_name):\n",
    "\n",
    "    mlflow.set_tag(\"Dataset_version\", cfg.mlflow.dataset_version)\n",
    "    mlflow.log_param(\"model_name\", cfg.model.name)\n",
    "\n",
    "    # ---------------------------\n",
    "    #   Загружаем датасет\n",
    "    # ---------------------------\n",
    "\n",
    "    dataset_runs = client.search_runs(\n",
    "        experiment_ids=[cfg.mlflow.experiment_name], \n",
    "        filter_string=f\"tags.mlflow.runName = 'Third dataset'\",\n",
    "        order_by=['attributes.end_time desc']\n",
    "    )\n",
    "\n",
    "    if not dataset_runs:\n",
    "        raise ValueError(\"Не найден run с датасетом 'Third dataset'\")\n",
    "\n",
    "    dataset_run_id = dataset_runs[0].info.run_id\n",
    "    print(f\"✅ Найден run с датасетом: {dataset_run_id}\")\n",
    "\n",
    "    dataset_path_in_run = \"datasets/third_experiment_dataset.csv\" \n",
    "    artifact_local_path = client.download_artifacts(dataset_run_id, dataset_path_in_run)\n",
    "\n",
    "    df = pd.read_csv(artifact_local_path)\n",
    "    print(f\"✅ Датасет загружен из run: {artifact_local_path}\")\n",
    "\n",
    "    # ---------------------------\n",
    "    #   ПОДГОТОВКА ДАННЫХ\n",
    "    # ---------------------------\n",
    "\n",
    "    # Кодируем лейблы\n",
    "    encoder = LabelEncoder()\n",
    "    df[\"labels\"] = encoder.fit_transform(df[\"label\"])\n",
    "    df[\"labels\"] = df[\"labels\"].astype(int)\n",
    "\n",
    "    mlflow.log_param(\"num_labels\", len(encoder.classes_))\n",
    "\n",
    "    # Разделяем на train/val/test\n",
    "    df_train, df_temp = train_test_split(\n",
    "        df,\n",
    "        test_size=1 - cfg.data.train_size,\n",
    "        random_state=cfg.data.random_state,\n",
    "        shuffle=True,\n",
    "        stratify=df[\"labels\"]\n",
    "    )\n",
    "\n",
    "    df_val, df_test = train_test_split(\n",
    "        df_temp,\n",
    "        test_size=cfg.data.val_size,\n",
    "        random_state=cfg.data.random_state,\n",
    "        shuffle=True,\n",
    "        stratify=df_temp[\"labels\"]\n",
    "    )\n",
    "\n",
    "    print(f\"📊 Размеры данных: Train={len(df_train)}, Val={len(df_val)}, Test={len(df_test)}\")\n",
    "\n",
    "    # ---------------------------\n",
    "    #   ПОДГОТОВКА ДАТАСЕТОВ (ИСПРАВЛЕННАЯ)\n",
    "    # ---------------------------\n",
    "\n",
    "    # Сбрасываем индексы чтобы избежать __index_level_0__\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_val = df_val.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "    # Создаем датасеты\n",
    "    dataset_train = Dataset.from_dict({\n",
    "        \"text\": df_train[\"span\"].tolist(),\n",
    "        \"labels\": df_train[\"labels\"].tolist()\n",
    "    })\n",
    "    \n",
    "    dataset_val = Dataset.from_dict({\n",
    "        \"text\": df_val[\"span\"].tolist(), \n",
    "        \"labels\": df_val[\"labels\"].tolist()\n",
    "    })\n",
    "    \n",
    "    dataset_test = Dataset.from_dict({\n",
    "        \"text\": df_test[\"span\"].tolist(),\n",
    "        \"labels\": df_test[\"labels\"].tolist()\n",
    "    })\n",
    "\n",
    "    # ---------------------------\n",
    "    #   ТОКЕНИЗАЦИЯ\n",
    "    # ---------------------------\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(cfg.model.name)\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        # Токенизируем только текст\n",
    "        tokenized = tokenizer(\n",
    "            examples[\"text\"],\n",
    "            truncation=True,\n",
    "            padding=False,\n",
    "            max_length=cfg.model.max_length\n",
    "        )\n",
    "        return tokenized\n",
    "\n",
    "    # Применяем токенизацию\n",
    "    tokenized_train = dataset_train.map(tokenize_function, batched=True)\n",
    "    tokenized_val = dataset_val.map(tokenize_function, batched=True)\n",
    "    tokenized_test = dataset_test.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Удаляем текстовую колонку после токенизации\n",
    "    tokenized_train = tokenized_train.remove_columns(['text'])\n",
    "    tokenized_val = tokenized_val.remove_columns(['text'])\n",
    "    tokenized_test = tokenized_test.remove_columns(['text'])\n",
    "\n",
    "    print(\"🔍 Проверка структуры данных после токенизации:\")\n",
    "    print(f\"Train columns: {tokenized_train.column_names}\")\n",
    "    print(f\"Sample train: {tokenized_train[0]}\")\n",
    "\n",
    "    # DataCollator для динамического паддинга\n",
    "    data_collator = DataCollatorWithPadding(\n",
    "        tokenizer=tokenizer,\n",
    "        padding=True,\n",
    "        max_length=cfg.model.max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # ---------------------------\n",
    "    #   ИНИЦИАЛИЗАЦИЯ МОДЕЛИ\n",
    "    # ---------------------------\n",
    "\n",
    "    num_labels = len(encoder.classes_)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        cfg.model.name,\n",
    "        num_labels=num_labels,\n",
    "        id2label={i: label for i, label in enumerate(encoder.classes_)},\n",
    "        label2id={label: i for i, label in enumerate(encoder.classes_)},\n",
    "        hidden_dropout_prob=cfg.model.dropout.hidden,\n",
    "        attention_probs_dropout_prob=cfg.model.dropout.attention,\n",
    "        classifier_dropout=cfg.model.dropout.classifier\n",
    "    )\n",
    "\n",
    "    # ---------------------------\n",
    "    #   TRAINING ARGUMENTS\n",
    "    # ---------------------------\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=cfg.training.output_dir,\n",
    "        num_train_epochs=cfg.training.num_train_epochs,\n",
    "        learning_rate=cfg.training.learning_rate,\n",
    "        per_device_train_batch_size=cfg.training.per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=cfg.training.per_device_eval_batch_size,\n",
    "        warmup_ratio=cfg.training.warmup_ratio,\n",
    "        lr_scheduler_type=cfg.training.lr_scheduler_type,\n",
    "        eval_strategy=cfg.training.eval_strategy,\n",
    "        save_strategy=cfg.training.save_strategy,\n",
    "        weight_decay=cfg.training.weight_decay,\n",
    "        logging_steps=cfg.training.logging_steps,\n",
    "        save_total_limit=cfg.training.save_total_limit,\n",
    "        max_grad_norm=cfg.training.max_grad_norm,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        dataloader_pin_memory=False,\n",
    "        dataloader_num_workers=0,\n",
    "        remove_unused_columns=True  # Включаем удаление лишних колонок\n",
    "    )\n",
    "\n",
    "    # ---------------------------\n",
    "    #   МЕТРИКИ\n",
    "    # ---------------------------\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        preds = np.argmax(logits, axis=1)\n",
    "\n",
    "        return {\n",
    "            \"f1\": f1_score(labels, preds, average=\"weighted\"),\n",
    "            \"accuracy\": accuracy_score(labels, preds)\n",
    "        }\n",
    "\n",
    "    # ---------------------------\n",
    "    #   ОБУЧЕНИЕ\n",
    "    # ---------------------------\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_train,\n",
    "        eval_dataset=tokenized_val,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator,\n",
    "        # tokenizer=tokenizer,  # УБИРАЕМ эту строку (deprecated)\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=cfg.training.early_stopping_patience)]\n",
    "    )\n",
    "\n",
    "    print(\"🚀 Начинаем обучение...\")\n",
    "    trainer.train()\n",
    "\n",
    "    # ---------------------------\n",
    "    #   ОЦЕНКА И ЛОГИРОВАНИЕ\n",
    "    # ---------------------------\n",
    "    \n",
    "    print(\"📊 Оцениваем модель на тестовом наборе...\")\n",
    "    test_predictions = trainer.predict(tokenized_test)\n",
    "    test_preds = np.argmax(test_predictions.predictions, axis=1)\n",
    "    test_labels = test_predictions.label_ids\n",
    "    \n",
    "    # Вычисляем метрики\n",
    "    test_f1 = f1_score(test_labels, test_preds, average=\"weighted\")\n",
    "    test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "    \n",
    "    # Логируем метрики\n",
    "    mlflow.log_metric(\"f1_score\", test_f1)\n",
    "    mlflow.log_metric(\"accuracy\", test_accuracy)\n",
    "    \n",
    "    print(f\"🎯 Финальные метрики на тесте:\")\n",
    "    print(f\"   F1-score: {test_f1:.4f}\")\n",
    "    print(f\"   Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "    # ---------------------------\n",
    "    #   СОХРАНЕНИЕ\n",
    "    # ---------------------------\n",
    "\n",
    "    # Создаем временные папки с правильными путями\n",
    "    model_dir = \"best_transformer_model\"\n",
    "    tokenizer_dir = \"best_transformer_tokenizer\"\n",
    "\n",
    "    # Сохраняем модель и токенизатор\n",
    "    trainer.save_model(model_dir)\n",
    "    tokenizer.save_pretrained(tokenizer_dir)\n",
    "\n",
    "    # Логируем папки как артефакты (ИСПРАВЛЕНО)\n",
    "    mlflow.log_artifacts(model_dir, artifact_path=\"model\")    # ✅ log_artifacts для папки\n",
    "    mlflow.log_artifacts(tokenizer_dir, artifact_path=\"tokenizer\")\n",
    "\n",
    "    # Сохраняем encoder\n",
    "    with open('label_encoder.pkl', 'wb') as f:\n",
    "        pickle.dump(encoder, f)\n",
    "    mlflow.log_artifact('label_encoder.pkl', artifact_path=\"preprocessing\")\n",
    "\n",
    "    # Очищаем временные файлы (опционально)\n",
    "    import shutil\n",
    "    shutil.rmtree(model_dir)\n",
    "    shutil.rmtree(tokenizer_dir)\n",
    "    os.remove('label_encoder.pkl')\n",
    "\n",
    "    print(\"✅ Трансформер успешно обучен и залогирован!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a2015c",
   "metadata": {},
   "source": [
    "#### Проверка результатов (инференс)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e9c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config(\"inference_transformers_third\")\n",
    "\n",
    "client = MlflowClient(tracking_uri=cfg.mlflow.tracking_uri)\n",
    "\n",
    "# ================================\n",
    "# 2. Ищем нужный run в MLflow\n",
    "# ================================\n",
    "print(\"Ищем run с моделью...\")\n",
    "\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[cfg.mlflow.experiment_id],\n",
    "    filter_string=f'attributes.run_name = \"{cfg.model.run_name}\"',  # ⚠️ исправлено на attributes.run_name\n",
    "    order_by=[\"attributes.end_time desc\"]\n",
    ")\n",
    "\n",
    "if not runs:\n",
    "    raise ValueError(f\"❌ Run '{cfg.model.run_name}' не найден!\")\n",
    "\n",
    "run_id = runs[0].info.run_id\n",
    "print(f\"✅ Найден run: {run_id}\")\n",
    "\n",
    "# ================================\n",
    "# 3. Скачиваем артефакты\n",
    "# ================================\n",
    "print(\"Скачиваем модель, токенизатор и энкодер...\")\n",
    "\n",
    "try:\n",
    "    model_dir = client.download_artifacts(run_id, cfg.model.artifacts_path)\n",
    "    tokenizer_dir = client.download_artifacts(run_id, cfg.model.tokenizer_path)\n",
    "    encoder_path = client.download_artifacts(run_id, \"preprocessing/label_encoder.pkl\")\n",
    "    \n",
    "    print(f\"📁 Модель скачана: {model_dir}\")\n",
    "    print(f\"📁 Токенизатор скачан: {tokenizer_dir}\")\n",
    "    print(f\"📁 Энкодер скачан: {encoder_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Ошибка загрузки артефактов: {e}\")\n",
    "    raise\n",
    "\n",
    "# ================================\n",
    "# 4. Загружаем модель в память\n",
    "# ================================\n",
    "print(\"Загружаем модель и компоненты...\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_dir)\n",
    "\n",
    "# Загружаем encoder\n",
    "with open(encoder_path, 'rb') as f:\n",
    "    encoder = pickle.load(f)\n",
    "\n",
    "print(\"✅ Все компоненты загружены\")\n",
    "\n",
    "# ================================\n",
    "# 5. Предсказание\n",
    "# ================================\n",
    "text = cfg.test_text\n",
    "print(f\"Тестовый текст: «{text}»\")\n",
    "\n",
    "# Конфиг токенизатора\n",
    "tokenizer_cfg = {k: v for k, v in cfg.tokenizer.items() if v is not None}\n",
    "\n",
    "# Токенизация\n",
    "inputs = tokenizer(text, **tokenizer_cfg)\n",
    "\n",
    "# Предсказание\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Обработка результатов\n",
    "pred_idx = probs.argmax().item()\n",
    "pred_prob = probs[0][pred_idx].item()\n",
    "\n",
    "# Используем наш encoder для получения оригинального названия класса\n",
    "pred_label = encoder.inverse_transform([pred_idx])[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(f\"Исходный текст: «{text}»\")\n",
    "print(f\"Предсказанная метка: {pred_label}\")\n",
    "print(f\"Вероятность: {pred_prob:.4f}\")\n",
    "print(\"\\nВсе вероятности:\")\n",
    "for i, p in enumerate(probs[0]):\n",
    "    label = encoder.inverse_transform([i])[0]\n",
    "    print(f\"  {label}: {p:.4f}\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e479c692",
   "metadata": {},
   "source": [
    "# Выбор лучшей модели (для инференса)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdf005a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "\n",
    "runs = client.search_runs(experiment_ids = ['0'],\n",
    "                          order_by = ['metrics.f1_score desc', 'metrics.accuracy desc'])\n",
    "\n",
    "print(runs[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
