{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a95fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_full_review(url):\n",
    "    \"\"\"\n",
    "    Парсит полную страницу отзыва\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Основной контейнер отзыва\n",
    "        review_block = soup.select_one('.reviewBlock')\n",
    "        if not review_block:\n",
    "            print(f\"Не найден контейнер отзыва для {url}\")\n",
    "            return None\n",
    "        \n",
    "        # Извлекаем данные\n",
    "        review_data = {}\n",
    "        \n",
    "        # Автор\n",
    "        author_element = review_block.select_one('.reviewer a')\n",
    "        review_data['author'] = author_element.get_text(strip=True) if author_element else 'N/A'\n",
    "        \n",
    "        # Рейтинг (из мета-тега)\n",
    "        rating_meta = review_block.select_one('meta[itemprop=\"ratingValue\"]')\n",
    "        review_data['rating'] = rating_meta['content'] if rating_meta else 'N/A'\n",
    "        \n",
    "        # Дата публикации\n",
    "        date_element = review_block.select_one('.dtreviewed')\n",
    "        review_data['full_date'] = date_element.get_text(strip=True) if date_element else 'N/A'\n",
    "        \n",
    "        # Заголовок отзыва\n",
    "        title_element = review_block.select_one('.reviewTitle a')\n",
    "        review_data['full_title'] = title_element.get_text(strip=True) if title_element else 'N/A'\n",
    "        \n",
    "        # Полный текст отзыва\n",
    "        review_body = review_block.select_one('[itemprop=\"reviewBody\"]')\n",
    "        if review_body:\n",
    "            # Удаляем скрипты и стили\n",
    "            for script in review_body([\"script\", \"style\"]):\n",
    "                script.decompose()\n",
    "            \n",
    "            # Получаем чистый текст\n",
    "            full_text = review_body.get_text(separator='\\n', strip=True)\n",
    "            # Убираем лишние пробелы и переносы\n",
    "            full_text = re.sub(r'\\n\\s*\\n', '\\n\\n', full_text)\n",
    "            review_data['full_text'] = full_text\n",
    "            \n",
    "            # Дополнительно: извлекаем отдельные элементы текста\n",
    "            paragraphs = review_body.find_all('p')\n",
    "            review_data['paragraphs_count'] = len(paragraphs)\n",
    "            \n",
    "            # Извлекаем цитаты\n",
    "            quotes = review_body.select('blockquote p')\n",
    "            review_data['quotes'] = [quote.get_text(strip=True) for quote in quotes]\n",
    "            \n",
    "            # Извлекаем списки (плюсы/минусы)\n",
    "            lists = review_body.find_all(['ul', 'ol'])\n",
    "            review_data['lists_count'] = len(lists)\n",
    "        else:\n",
    "            review_data['full_text'] = 'N/A'\n",
    "            review_data['paragraphs_count'] = 0\n",
    "            review_data['quotes'] = []\n",
    "            review_data['lists_count'] = 0\n",
    "        \n",
    "        # Количество изображений в отзыве\n",
    "        images = review_block.select('.inline-image img')\n",
    "        review_data['images_count'] = len(images)\n",
    "        review_data['image_urls'] = []\n",
    "        \n",
    "        for img in images:\n",
    "            img_src = img.get('src') or img.get('data-original')\n",
    "            if img_src and not img_src.startswith('data:'):\n",
    "                if img_src.startswith('//'):\n",
    "                    img_src = 'https:' + img_src\n",
    "                elif img_src.startswith('/'):\n",
    "                    img_src = 'https://irecommend.ru' + img_src\n",
    "                review_data['image_urls'].append(img_src)\n",
    "        \n",
    "        # Вердикт (рекомендует/не рекомендует)\n",
    "        verdict_element = review_block.select_one('.verdict')\n",
    "        review_data['verdict'] = verdict_element.get_text(strip=True) if verdict_element else 'N/A'\n",
    "        \n",
    "        # Дополнительная информация\n",
    "        review_data['url'] = url\n",
    "        review_data['timestamp'] = time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        print(f\"Обработан отзыв: {review_data['full_title'][:50]}...\")\n",
    "        return review_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при парсинге {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_all_reviews(df, start_from=0, delay=2):\n",
    "    \"\"\"\n",
    "    Обрабатывает все ссылки на отзывы из DataFrame\n",
    "    \"\"\"\n",
    "    full_reviews_data = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        if idx < start_from:\n",
    "            continue\n",
    "            \n",
    "        url = row['full_review_link']\n",
    "        print(f\"Обработка отзыва {idx + 1}/{len(df)}: {url}\")\n",
    "        \n",
    "        review_data = parse_full_review(url)\n",
    "        if review_data:\n",
    "            # Объединяем с исходными данными\n",
    "            combined_data = {**row.to_dict(), **review_data}\n",
    "            full_reviews_data.append(combined_data)\n",
    "        \n",
    "        # Задержка между запросами\n",
    "        time.sleep(delay)\n",
    "    \n",
    "    return full_reviews_data\n",
    "\n",
    "# Основной код\n",
    "if __name__ == \"__main__\":\n",
    "    # Загружаем CSV с собранными отзывами\n",
    "    df = pd.read_csv('chips_reviews.csv')\n",
    "    \n",
    "    print(f\"Всего отзывов для обработки: {len(df)}\")\n",
    "    \n",
    "    # Обрабатываем все отзывы\n",
    "    all_full_reviews = process_all_reviews(df, start_from=0, delay=2)\n",
    "    \n",
    "    # Сохраняем результаты\n",
    "    if all_full_reviews:\n",
    "        full_df = pd.DataFrame(all_full_reviews)\n",
    "        \n",
    "        # Сохраняем в CSV\n",
    "        full_df.to_csv('chips_reviews_full.csv', index=False, encoding='utf-8')\n",
    "        \n",
    "        # Сохраняем в JSON\n",
    "        full_df.to_json('chips_reviews_full.json', orient='records', force_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"\\nУспешно обработано {len(all_full_reviews)} полных отзывов\")\n",
    "        print(\"Данные сохранены в chips_reviews_full.csv и chips_reviews_full.json\")\n",
    "        \n",
    "        # Выводим пример данных\n",
    "        print(\"\\nПример данных:\")\n",
    "        print(full_df[['author', 'rating', 'full_title', 'images_count']].head())\n",
    "    else:\n",
    "        print(\"Не удалось обработать ни одного отзыва\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ec64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('chips_reviews_full.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc24f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['full_text'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
